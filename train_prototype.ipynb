{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import copy\n",
    "import math\n",
    "import argparse\n",
    "import numpy as np\n",
    "from time import time\n",
    "from tqdm import tqdm\n",
    "from easydict import EasyDict\n",
    "\n",
    "import torch\n",
    "import torch.distributed as dist\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "\n",
    "import models\n",
    "\n",
    "# Define the transformation to apply to the dataset\n",
    "# transform = transforms.Compose([\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "# ])\n",
    "\n",
    "transform_train = transforms.Compose(\n",
    "    [\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Download and load the CIFAR10 training dataset\n",
    "\n",
    "train_set = torchvision.datasets.CIFAR10(root='./data/', train=True, download=True, transform=transform_train)\n",
    "\n",
    "# Download and load the CIFAR10 test dataset\n",
    "# test_set = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "# testloader = torch.utils.data.DataLoader(test_set, batch_size=4, shuffle=False, num_workers=2)\n",
    "\n",
    "# Define the classes for CIFAR10\n",
    "# classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "######## CHECK METADATA #########\n",
    "metadata = EasyDict(\n",
    "    {\n",
    "        \"image_size\": 32,\n",
    "        \"num_classes\": 10,\n",
    "        \"train_images\": 50000,\n",
    "        \"val_images\": 10000,\n",
    "        \"num_channels\": 3,\n",
    "    }\n",
    ")\n",
    "############# PARAMETERS #############\n",
    "DIFFUSION_STEPS = 100\n",
    "BATCH_SIZE = 32 # OR 128\n",
    "LEARNING_RATE = 0.0001\n",
    "EMA_W = 0.75 # Exponential Moving Average Weight\n",
    "EPOCHS = 100\n",
    "PRETRAINED_MODEL = \"\"\n",
    "SAVE_MODEL = True\n",
    "SAVE_MODEL_PATH = \"./saved_models/\"\n",
    "SAVE_IMAGES_PATH = \"./images/\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if os.path.exists(SAVE_MODEL_PATH) == False:\n",
    "    os.makedirs(SAVE_MODEL_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class loss_logger:\n",
    "    def __init__(self, max_steps):\n",
    "        self.max_steps = max_steps\n",
    "        self.loss = []\n",
    "        self.start_time = time()\n",
    "        self.ema_loss = None\n",
    "        self.ema_w = EMA_W\n",
    "\n",
    "    def log(self, v, display=False):\n",
    "        self.loss.append(v)\n",
    "        if self.ema_loss is None:\n",
    "            self.ema_loss = v\n",
    "        else:\n",
    "            self.ema_loss = self.ema_w * self.ema_loss + (1 - self.ema_w) * v\n",
    "\n",
    "        if display:\n",
    "            print(\n",
    "                f\"Steps: {len(self.loss)}/{self.max_steps} \\t loss (ema): {self.ema_loss:.3f} \"\n",
    "                + f\"\\t Time elapsed: {(time() - self.start_time)/3600:.3f} hr\"\n",
    "            )\n",
    "\n",
    "\n",
    "def train_one_epoch(\n",
    "    model,\n",
    "    dataloader,\n",
    "    diffusion,\n",
    "    optimizer,\n",
    "    logger,\n",
    "    lrs,\n",
    "    ema_dict,\n",
    "    device,\n",
    "):\n",
    "    model.train()\n",
    "    for step, (images, labels) in enumerate(dataloader):\n",
    "        assert (images.max().item() <= 1) and (0 <= images.min().item())\n",
    "\n",
    "        # must use [-1, 1] pixel range for images\n",
    "        images, labels = (\n",
    "            2 * images.to(device) - 1,\n",
    "            None, # class_cond = False\n",
    "        )\n",
    "        t = torch.randint(diffusion.timesteps, (len(images),), dtype=torch.int64).to(\n",
    "            device\n",
    "        )\n",
    "        xt, eps = diffusion.sample_from_forward_process(images, t)\n",
    "        # print(xt.shape,t.shape,images.shape)\n",
    "        pred_eps = model(xt, t)\n",
    "        # print(pred_eps.shape, eps.shape)\n",
    "        loss = ((pred_eps - eps) ** 2).mean()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if lrs is not None:\n",
    "            lrs.step()\n",
    "\n",
    "        # update ema_dict\n",
    "        # if args.local_rank == 0:\n",
    "        new_dict = model.state_dict()\n",
    "        for (k, v) in ema_dict.items():\n",
    "            ema_dict[k] = (\n",
    "                EMA_W * ema_dict[k] + (1 - EMA_W) * new_dict[k]\n",
    "            )\n",
    "        logger.log(loss.item(), display=not step % 100)\n",
    "\n",
    "    return ema_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Auxiliary function to handle the model inference and generate images from the diffusion process.'''\n",
    "\n",
    "def generate_N_images(\n",
    "    N,\n",
    "    model,\n",
    "    diffusion,\n",
    "    xT=None,\n",
    "    sampling_steps=250,\n",
    "    batch_size=32,\n",
    "    num_channels=3,\n",
    "    image_size=32,\n",
    "#    num_classes=None,\n",
    "):\n",
    "    \"\"\"use this function to generate any number of images from a given\n",
    "        diffusion model and diffusion process.\n",
    "\n",
    "    Args:\n",
    "        N : Number of images\n",
    "        model : Diffusion model\n",
    "        diffusion : Diffusion process\n",
    "        xT : Starting instantiation of noise vector.\n",
    "        sampling_steps : Number of sampling steps.\n",
    "        batch_size : Batch-size for sampling.\n",
    "        num_channels : Number of channels in the image.\n",
    "        image_size : Image size (assuming square images).\n",
    "        num_classes : Number of classes in the dataset (needed for class-conditioned models)\n",
    "\n",
    "\n",
    "    Returns: Numpy array with N images and corresponding labels.\n",
    "    \"\"\"\n",
    "\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    samples, labels, num_samples = [], [], 0\n",
    "    num_processes, group = dist.get_world_size(), dist.group.WORLD\n",
    "    with tqdm(total=math.ceil(N / (batch_size * num_processes))) as pbar:\n",
    "        while num_samples < N:\n",
    "            if xT is None:\n",
    "                xT = (\n",
    "                    torch.randn(batch_size, num_channels, image_size, image_size)\n",
    "                    .float()\n",
    "                    .to(device)\n",
    "                )\n",
    "            else:\n",
    "                y = None\n",
    "            gen_images = diffusion.sample_from_reverse_process(\n",
    "                model, xT, sampling_steps, {\"y\": y},\n",
    "            )\n",
    "            samples_list = [torch.zeros_like(gen_images) for _ in range(num_processes)]\n",
    "\n",
    "            dist.all_gather(samples_list, gen_images, group)\n",
    "            samples.append(torch.cat(samples_list).detach().cpu().numpy())\n",
    "            num_samples += len(xT) * num_processes\n",
    "            pbar.update(1)\n",
    "    samples = np.concatenate(samples).transpose(0, 2, 3, 1)[:N]\n",
    "    samples = (127.5 * (samples + 1)).astype(np.uint8)\n",
    "    return samples\n",
    "\n",
    "def load_model(model, model_path):\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "Training from scratch\n",
      "Training dataset loaded: Number of batches: 1563, Number of images: 50000\n",
      "Steps: 1/156300 \t loss (ema): 1.000 \t Time elapsed: 0.000 hr\n",
      "Steps: 101/156300 \t loss (ema): 0.284 \t Time elapsed: 0.007 hr\n",
      "Steps: 201/156300 \t loss (ema): 0.102 \t Time elapsed: 0.013 hr\n",
      "Steps: 301/156300 \t loss (ema): 0.089 \t Time elapsed: 0.020 hr\n",
      "Steps: 401/156300 \t loss (ema): 0.077 \t Time elapsed: 0.027 hr\n",
      "Steps: 501/156300 \t loss (ema): 0.068 \t Time elapsed: 0.033 hr\n",
      "Steps: 601/156300 \t loss (ema): 0.059 \t Time elapsed: 0.040 hr\n",
      "Steps: 701/156300 \t loss (ema): 0.067 \t Time elapsed: 0.047 hr\n",
      "Steps: 801/156300 \t loss (ema): 0.063 \t Time elapsed: 0.053 hr\n",
      "Steps: 901/156300 \t loss (ema): 0.066 \t Time elapsed: 0.060 hr\n",
      "Steps: 1001/156300 \t loss (ema): 0.064 \t Time elapsed: 0.067 hr\n",
      "Steps: 1101/156300 \t loss (ema): 0.055 \t Time elapsed: 0.073 hr\n",
      "Steps: 1201/156300 \t loss (ema): 0.055 \t Time elapsed: 0.080 hr\n",
      "Steps: 1301/156300 \t loss (ema): 0.064 \t Time elapsed: 0.087 hr\n",
      "Steps: 1401/156300 \t loss (ema): 0.061 \t Time elapsed: 0.093 hr\n",
      "Steps: 1501/156300 \t loss (ema): 0.076 \t Time elapsed: 0.100 hr\n",
      "Epoch 0 completed\n",
      "Steps: 1564/156300 \t loss (ema): 0.064 \t Time elapsed: 0.104 hr\n",
      "Steps: 1664/156300 \t loss (ema): 0.063 \t Time elapsed: 0.111 hr\n",
      "Steps: 1764/156300 \t loss (ema): 0.060 \t Time elapsed: 0.118 hr\n",
      "Steps: 1864/156300 \t loss (ema): 0.064 \t Time elapsed: 0.124 hr\n",
      "Steps: 1964/156300 \t loss (ema): 0.067 \t Time elapsed: 0.131 hr\n",
      "Steps: 2064/156300 \t loss (ema): 0.068 \t Time elapsed: 0.138 hr\n",
      "Steps: 2164/156300 \t loss (ema): 0.057 \t Time elapsed: 0.144 hr\n",
      "Steps: 2264/156300 \t loss (ema): 0.053 \t Time elapsed: 0.151 hr\n",
      "Steps: 2364/156300 \t loss (ema): 0.065 \t Time elapsed: 0.158 hr\n",
      "Steps: 2464/156300 \t loss (ema): 0.057 \t Time elapsed: 0.164 hr\n",
      "Steps: 2564/156300 \t loss (ema): 0.064 \t Time elapsed: 0.171 hr\n",
      "Steps: 2664/156300 \t loss (ema): 0.052 \t Time elapsed: 0.178 hr\n",
      "Steps: 2764/156300 \t loss (ema): 0.062 \t Time elapsed: 0.184 hr\n",
      "Steps: 2864/156300 \t loss (ema): 0.054 \t Time elapsed: 0.191 hr\n",
      "Steps: 2964/156300 \t loss (ema): 0.069 \t Time elapsed: 0.198 hr\n",
      "Steps: 3064/156300 \t loss (ema): 0.061 \t Time elapsed: 0.204 hr\n",
      "Steps: 3127/156300 \t loss (ema): 0.062 \t Time elapsed: 0.209 hr\n",
      "Steps: 3227/156300 \t loss (ema): 0.048 \t Time elapsed: 0.215 hr\n",
      "Steps: 3327/156300 \t loss (ema): 0.059 \t Time elapsed: 0.222 hr\n",
      "Steps: 3427/156300 \t loss (ema): 0.056 \t Time elapsed: 0.229 hr\n",
      "Steps: 3527/156300 \t loss (ema): 0.059 \t Time elapsed: 0.235 hr\n",
      "Steps: 3627/156300 \t loss (ema): 0.053 \t Time elapsed: 0.242 hr\n",
      "Steps: 3727/156300 \t loss (ema): 0.070 \t Time elapsed: 0.249 hr\n",
      "Steps: 3827/156300 \t loss (ema): 0.068 \t Time elapsed: 0.255 hr\n",
      "Steps: 3927/156300 \t loss (ema): 0.056 \t Time elapsed: 0.262 hr\n",
      "Steps: 4027/156300 \t loss (ema): 0.059 \t Time elapsed: 0.269 hr\n",
      "Steps: 4127/156300 \t loss (ema): 0.064 \t Time elapsed: 0.276 hr\n",
      "Steps: 4227/156300 \t loss (ema): 0.052 \t Time elapsed: 0.282 hr\n",
      "Steps: 4327/156300 \t loss (ema): 0.051 \t Time elapsed: 0.289 hr\n",
      "Steps: 4427/156300 \t loss (ema): 0.064 \t Time elapsed: 0.296 hr\n",
      "Steps: 4527/156300 \t loss (ema): 0.053 \t Time elapsed: 0.302 hr\n",
      "Steps: 4627/156300 \t loss (ema): 0.063 \t Time elapsed: 0.309 hr\n",
      "Steps: 4690/156300 \t loss (ema): 0.071 \t Time elapsed: 0.313 hr\n",
      "Steps: 4790/156300 \t loss (ema): 0.057 \t Time elapsed: 0.320 hr\n",
      "Steps: 4890/156300 \t loss (ema): 0.054 \t Time elapsed: 0.327 hr\n",
      "Steps: 4990/156300 \t loss (ema): 0.055 \t Time elapsed: 0.333 hr\n",
      "Steps: 5090/156300 \t loss (ema): 0.065 \t Time elapsed: 0.340 hr\n",
      "Steps: 5190/156300 \t loss (ema): 0.057 \t Time elapsed: 0.347 hr\n",
      "Steps: 5290/156300 \t loss (ema): 0.056 \t Time elapsed: 0.353 hr\n",
      "Steps: 5390/156300 \t loss (ema): 0.061 \t Time elapsed: 0.360 hr\n",
      "Steps: 5490/156300 \t loss (ema): 0.058 \t Time elapsed: 0.367 hr\n",
      "Steps: 5590/156300 \t loss (ema): 0.060 \t Time elapsed: 0.373 hr\n",
      "Steps: 5690/156300 \t loss (ema): 0.066 \t Time elapsed: 0.380 hr\n",
      "Steps: 5790/156300 \t loss (ema): 0.063 \t Time elapsed: 0.387 hr\n",
      "Steps: 5890/156300 \t loss (ema): 0.051 \t Time elapsed: 0.393 hr\n",
      "Steps: 5990/156300 \t loss (ema): 0.057 \t Time elapsed: 0.400 hr\n",
      "Steps: 6090/156300 \t loss (ema): 0.061 \t Time elapsed: 0.406 hr\n",
      "Steps: 6190/156300 \t loss (ema): 0.057 \t Time elapsed: 0.413 hr\n",
      "Steps: 6253/156300 \t loss (ema): 0.054 \t Time elapsed: 0.417 hr\n",
      "Steps: 6353/156300 \t loss (ema): 0.052 \t Time elapsed: 0.424 hr\n",
      "Steps: 6453/156300 \t loss (ema): 0.061 \t Time elapsed: 0.431 hr\n",
      "Steps: 6553/156300 \t loss (ema): 0.062 \t Time elapsed: 0.437 hr\n",
      "Steps: 6653/156300 \t loss (ema): 0.059 \t Time elapsed: 0.444 hr\n",
      "Steps: 6753/156300 \t loss (ema): 0.055 \t Time elapsed: 0.451 hr\n",
      "Steps: 6853/156300 \t loss (ema): 0.062 \t Time elapsed: 0.457 hr\n",
      "Steps: 6953/156300 \t loss (ema): 0.047 \t Time elapsed: 0.464 hr\n",
      "Steps: 7053/156300 \t loss (ema): 0.056 \t Time elapsed: 0.471 hr\n",
      "Steps: 7153/156300 \t loss (ema): 0.069 \t Time elapsed: 0.477 hr\n",
      "Steps: 7253/156300 \t loss (ema): 0.059 \t Time elapsed: 0.484 hr\n",
      "Steps: 7353/156300 \t loss (ema): 0.056 \t Time elapsed: 0.491 hr\n",
      "Steps: 7453/156300 \t loss (ema): 0.061 \t Time elapsed: 0.497 hr\n",
      "Steps: 7553/156300 \t loss (ema): 0.054 \t Time elapsed: 0.504 hr\n",
      "Steps: 7653/156300 \t loss (ema): 0.064 \t Time elapsed: 0.511 hr\n",
      "Steps: 7753/156300 \t loss (ema): 0.058 \t Time elapsed: 0.517 hr\n",
      "Steps: 7816/156300 \t loss (ema): 0.060 \t Time elapsed: 0.522 hr\n",
      "Steps: 7916/156300 \t loss (ema): 0.064 \t Time elapsed: 0.528 hr\n",
      "Steps: 8016/156300 \t loss (ema): 0.055 \t Time elapsed: 0.535 hr\n",
      "Steps: 8116/156300 \t loss (ema): 0.065 \t Time elapsed: 0.542 hr\n",
      "Steps: 8216/156300 \t loss (ema): 0.055 \t Time elapsed: 0.548 hr\n",
      "Steps: 8316/156300 \t loss (ema): 0.057 \t Time elapsed: 0.555 hr\n",
      "Steps: 8416/156300 \t loss (ema): 0.053 \t Time elapsed: 0.562 hr\n",
      "Steps: 8516/156300 \t loss (ema): 0.050 \t Time elapsed: 0.568 hr\n",
      "Steps: 8616/156300 \t loss (ema): 0.055 \t Time elapsed: 0.575 hr\n",
      "Steps: 8716/156300 \t loss (ema): 0.057 \t Time elapsed: 0.582 hr\n",
      "Steps: 8816/156300 \t loss (ema): 0.057 \t Time elapsed: 0.589 hr\n",
      "Steps: 8916/156300 \t loss (ema): 0.055 \t Time elapsed: 0.595 hr\n",
      "Steps: 9016/156300 \t loss (ema): 0.058 \t Time elapsed: 0.602 hr\n",
      "Steps: 9116/156300 \t loss (ema): 0.059 \t Time elapsed: 0.609 hr\n",
      "Steps: 9216/156300 \t loss (ema): 0.041 \t Time elapsed: 0.615 hr\n",
      "Steps: 9316/156300 \t loss (ema): 0.064 \t Time elapsed: 0.622 hr\n",
      "Steps: 9379/156300 \t loss (ema): 0.047 \t Time elapsed: 0.626 hr\n",
      "Steps: 9479/156300 \t loss (ema): 0.066 \t Time elapsed: 0.633 hr\n",
      "Steps: 9579/156300 \t loss (ema): 0.050 \t Time elapsed: 0.640 hr\n",
      "Steps: 9679/156300 \t loss (ema): 0.062 \t Time elapsed: 0.646 hr\n",
      "Steps: 9779/156300 \t loss (ema): 0.057 \t Time elapsed: 0.653 hr\n",
      "Steps: 9879/156300 \t loss (ema): 0.052 \t Time elapsed: 0.660 hr\n",
      "Steps: 9979/156300 \t loss (ema): 0.052 \t Time elapsed: 0.666 hr\n",
      "Steps: 10079/156300 \t loss (ema): 0.053 \t Time elapsed: 0.673 hr\n",
      "Steps: 10179/156300 \t loss (ema): 0.049 \t Time elapsed: 0.680 hr\n",
      "Steps: 10279/156300 \t loss (ema): 0.046 \t Time elapsed: 0.686 hr\n",
      "Steps: 10379/156300 \t loss (ema): 0.049 \t Time elapsed: 0.693 hr\n",
      "Steps: 10479/156300 \t loss (ema): 0.058 \t Time elapsed: 0.700 hr\n",
      "Steps: 10579/156300 \t loss (ema): 0.047 \t Time elapsed: 0.706 hr\n",
      "Steps: 10679/156300 \t loss (ema): 0.066 \t Time elapsed: 0.713 hr\n",
      "Steps: 10779/156300 \t loss (ema): 0.053 \t Time elapsed: 0.720 hr\n",
      "Steps: 10879/156300 \t loss (ema): 0.050 \t Time elapsed: 0.726 hr\n",
      "Steps: 10942/156300 \t loss (ema): 0.051 \t Time elapsed: 0.730 hr\n",
      "Steps: 11042/156300 \t loss (ema): 0.058 \t Time elapsed: 0.737 hr\n",
      "Steps: 11142/156300 \t loss (ema): 0.055 \t Time elapsed: 0.744 hr\n",
      "Steps: 11242/156300 \t loss (ema): 0.058 \t Time elapsed: 0.750 hr\n",
      "Steps: 11342/156300 \t loss (ema): 0.058 \t Time elapsed: 0.757 hr\n",
      "Steps: 11442/156300 \t loss (ema): 0.062 \t Time elapsed: 0.764 hr\n",
      "Steps: 11542/156300 \t loss (ema): 0.052 \t Time elapsed: 0.770 hr\n",
      "Steps: 11642/156300 \t loss (ema): 0.061 \t Time elapsed: 0.777 hr\n",
      "Steps: 11742/156300 \t loss (ema): 0.056 \t Time elapsed: 0.784 hr\n",
      "Steps: 11842/156300 \t loss (ema): 0.057 \t Time elapsed: 0.790 hr\n",
      "Steps: 11942/156300 \t loss (ema): 0.059 \t Time elapsed: 0.797 hr\n",
      "Steps: 12042/156300 \t loss (ema): 0.052 \t Time elapsed: 0.804 hr\n",
      "Steps: 12142/156300 \t loss (ema): 0.051 \t Time elapsed: 0.810 hr\n",
      "Steps: 12242/156300 \t loss (ema): 0.063 \t Time elapsed: 0.817 hr\n",
      "Steps: 12342/156300 \t loss (ema): 0.057 \t Time elapsed: 0.824 hr\n",
      "Steps: 12442/156300 \t loss (ema): 0.048 \t Time elapsed: 0.830 hr\n",
      "Steps: 12505/156300 \t loss (ema): 0.055 \t Time elapsed: 0.835 hr\n",
      "Steps: 12605/156300 \t loss (ema): 0.056 \t Time elapsed: 0.841 hr\n",
      "Steps: 12705/156300 \t loss (ema): 0.059 \t Time elapsed: 0.848 hr\n",
      "Steps: 12805/156300 \t loss (ema): 0.059 \t Time elapsed: 0.855 hr\n",
      "Steps: 12905/156300 \t loss (ema): 0.059 \t Time elapsed: 0.861 hr\n",
      "Steps: 13005/156300 \t loss (ema): 0.058 \t Time elapsed: 0.868 hr\n",
      "Steps: 13105/156300 \t loss (ema): 0.064 \t Time elapsed: 0.875 hr\n",
      "Steps: 13205/156300 \t loss (ema): 0.047 \t Time elapsed: 0.881 hr\n",
      "Steps: 13305/156300 \t loss (ema): 0.049 \t Time elapsed: 0.888 hr\n",
      "Steps: 13405/156300 \t loss (ema): 0.064 \t Time elapsed: 0.895 hr\n",
      "Steps: 13505/156300 \t loss (ema): 0.057 \t Time elapsed: 0.901 hr\n",
      "Steps: 13605/156300 \t loss (ema): 0.052 \t Time elapsed: 0.908 hr\n",
      "Steps: 13705/156300 \t loss (ema): 0.049 \t Time elapsed: 0.915 hr\n",
      "Steps: 13805/156300 \t loss (ema): 0.054 \t Time elapsed: 0.921 hr\n",
      "Steps: 13905/156300 \t loss (ema): 0.061 \t Time elapsed: 0.928 hr\n",
      "Steps: 14005/156300 \t loss (ema): 0.056 \t Time elapsed: 0.935 hr\n",
      "Steps: 14068/156300 \t loss (ema): 0.052 \t Time elapsed: 0.939 hr\n",
      "Steps: 14168/156300 \t loss (ema): 0.052 \t Time elapsed: 0.946 hr\n",
      "Steps: 14268/156300 \t loss (ema): 0.056 \t Time elapsed: 0.952 hr\n",
      "Steps: 14368/156300 \t loss (ema): 0.061 \t Time elapsed: 0.959 hr\n",
      "Steps: 14468/156300 \t loss (ema): 0.053 \t Time elapsed: 0.966 hr\n",
      "Steps: 14568/156300 \t loss (ema): 0.061 \t Time elapsed: 0.972 hr\n",
      "Steps: 14668/156300 \t loss (ema): 0.062 \t Time elapsed: 0.979 hr\n",
      "Steps: 14768/156300 \t loss (ema): 0.054 \t Time elapsed: 0.986 hr\n",
      "Steps: 14868/156300 \t loss (ema): 0.057 \t Time elapsed: 0.993 hr\n",
      "Steps: 14968/156300 \t loss (ema): 0.058 \t Time elapsed: 0.999 hr\n",
      "Steps: 15068/156300 \t loss (ema): 0.057 \t Time elapsed: 1.006 hr\n",
      "Steps: 15168/156300 \t loss (ema): 0.056 \t Time elapsed: 1.013 hr\n",
      "Steps: 15268/156300 \t loss (ema): 0.056 \t Time elapsed: 1.019 hr\n",
      "Steps: 15368/156300 \t loss (ema): 0.050 \t Time elapsed: 1.026 hr\n",
      "Steps: 15468/156300 \t loss (ema): 0.063 \t Time elapsed: 1.033 hr\n",
      "Steps: 15568/156300 \t loss (ema): 0.056 \t Time elapsed: 1.039 hr\n",
      "Steps: 15631/156300 \t loss (ema): 0.060 \t Time elapsed: 1.043 hr\n",
      "Steps: 15731/156300 \t loss (ema): 0.062 \t Time elapsed: 1.050 hr\n",
      "Steps: 15831/156300 \t loss (ema): 0.053 \t Time elapsed: 1.057 hr\n",
      "Steps: 15931/156300 \t loss (ema): 0.057 \t Time elapsed: 1.063 hr\n",
      "Steps: 16031/156300 \t loss (ema): 0.061 \t Time elapsed: 1.070 hr\n",
      "Steps: 16131/156300 \t loss (ema): 0.059 \t Time elapsed: 1.077 hr\n",
      "Steps: 16231/156300 \t loss (ema): 0.054 \t Time elapsed: 1.083 hr\n",
      "Steps: 16331/156300 \t loss (ema): 0.056 \t Time elapsed: 1.090 hr\n",
      "Steps: 16431/156300 \t loss (ema): 0.062 \t Time elapsed: 1.097 hr\n",
      "Steps: 16531/156300 \t loss (ema): 0.069 \t Time elapsed: 1.103 hr\n",
      "Steps: 16631/156300 \t loss (ema): 0.059 \t Time elapsed: 1.110 hr\n",
      "Steps: 16731/156300 \t loss (ema): 0.050 \t Time elapsed: 1.117 hr\n",
      "Steps: 16831/156300 \t loss (ema): 0.055 \t Time elapsed: 1.123 hr\n",
      "Steps: 16931/156300 \t loss (ema): 0.064 \t Time elapsed: 1.130 hr\n",
      "Steps: 17031/156300 \t loss (ema): 0.066 \t Time elapsed: 1.137 hr\n",
      "Steps: 17131/156300 \t loss (ema): 0.058 \t Time elapsed: 1.143 hr\n",
      "Epoch 10 completed\n",
      "Steps: 17194/156300 \t loss (ema): 0.047 \t Time elapsed: 1.148 hr\n",
      "Steps: 17294/156300 \t loss (ema): 0.057 \t Time elapsed: 1.154 hr\n",
      "Steps: 17394/156300 \t loss (ema): 0.053 \t Time elapsed: 1.161 hr\n",
      "Steps: 17494/156300 \t loss (ema): 0.047 \t Time elapsed: 1.168 hr\n",
      "Steps: 17594/156300 \t loss (ema): 0.056 \t Time elapsed: 1.174 hr\n",
      "Steps: 17694/156300 \t loss (ema): 0.049 \t Time elapsed: 1.181 hr\n",
      "Steps: 17794/156300 \t loss (ema): 0.062 \t Time elapsed: 1.188 hr\n",
      "Steps: 17894/156300 \t loss (ema): 0.060 \t Time elapsed: 1.194 hr\n",
      "Steps: 17994/156300 \t loss (ema): 0.054 \t Time elapsed: 1.201 hr\n",
      "Steps: 18094/156300 \t loss (ema): 0.054 \t Time elapsed: 1.208 hr\n",
      "Steps: 18194/156300 \t loss (ema): 0.048 \t Time elapsed: 1.215 hr\n",
      "Steps: 18294/156300 \t loss (ema): 0.054 \t Time elapsed: 1.221 hr\n",
      "Steps: 18394/156300 \t loss (ema): 0.060 \t Time elapsed: 1.228 hr\n",
      "Steps: 18494/156300 \t loss (ema): 0.050 \t Time elapsed: 1.235 hr\n",
      "Steps: 18594/156300 \t loss (ema): 0.053 \t Time elapsed: 1.241 hr\n",
      "Steps: 18694/156300 \t loss (ema): 0.057 \t Time elapsed: 1.248 hr\n",
      "Steps: 18757/156300 \t loss (ema): 0.058 \t Time elapsed: 1.252 hr\n",
      "Steps: 18857/156300 \t loss (ema): 0.046 \t Time elapsed: 1.259 hr\n",
      "Steps: 18957/156300 \t loss (ema): 0.049 \t Time elapsed: 1.266 hr\n",
      "Steps: 19057/156300 \t loss (ema): 0.056 \t Time elapsed: 1.272 hr\n",
      "Steps: 19157/156300 \t loss (ema): 0.054 \t Time elapsed: 1.279 hr\n",
      "Steps: 19257/156300 \t loss (ema): 0.058 \t Time elapsed: 1.286 hr\n",
      "Steps: 19357/156300 \t loss (ema): 0.060 \t Time elapsed: 1.292 hr\n",
      "Steps: 19457/156300 \t loss (ema): 0.059 \t Time elapsed: 1.299 hr\n",
      "Steps: 19557/156300 \t loss (ema): 0.056 \t Time elapsed: 1.306 hr\n",
      "Steps: 19657/156300 \t loss (ema): 0.051 \t Time elapsed: 1.312 hr\n",
      "Steps: 19757/156300 \t loss (ema): 0.049 \t Time elapsed: 1.319 hr\n",
      "Steps: 19857/156300 \t loss (ema): 0.052 \t Time elapsed: 1.326 hr\n",
      "Steps: 19957/156300 \t loss (ema): 0.050 \t Time elapsed: 1.333 hr\n",
      "Steps: 20057/156300 \t loss (ema): 0.064 \t Time elapsed: 1.339 hr\n",
      "Steps: 20157/156300 \t loss (ema): 0.056 \t Time elapsed: 1.346 hr\n",
      "Steps: 20257/156300 \t loss (ema): 0.053 \t Time elapsed: 1.353 hr\n",
      "Steps: 20320/156300 \t loss (ema): 0.053 \t Time elapsed: 1.357 hr\n",
      "Steps: 20420/156300 \t loss (ema): 0.057 \t Time elapsed: 1.364 hr\n",
      "Steps: 20520/156300 \t loss (ema): 0.052 \t Time elapsed: 1.370 hr\n",
      "Steps: 20620/156300 \t loss (ema): 0.057 \t Time elapsed: 1.377 hr\n",
      "Steps: 20720/156300 \t loss (ema): 0.054 \t Time elapsed: 1.384 hr\n",
      "Steps: 20820/156300 \t loss (ema): 0.058 \t Time elapsed: 1.390 hr\n",
      "Steps: 20920/156300 \t loss (ema): 0.056 \t Time elapsed: 1.397 hr\n",
      "Steps: 21020/156300 \t loss (ema): 0.049 \t Time elapsed: 1.404 hr\n",
      "Steps: 21120/156300 \t loss (ema): 0.060 \t Time elapsed: 1.410 hr\n",
      "Steps: 21220/156300 \t loss (ema): 0.055 \t Time elapsed: 1.417 hr\n",
      "Steps: 21320/156300 \t loss (ema): 0.047 \t Time elapsed: 1.423 hr\n",
      "Steps: 21420/156300 \t loss (ema): 0.051 \t Time elapsed: 1.430 hr\n",
      "Steps: 21520/156300 \t loss (ema): 0.050 \t Time elapsed: 1.437 hr\n",
      "Steps: 21620/156300 \t loss (ema): 0.057 \t Time elapsed: 1.443 hr\n",
      "Steps: 21720/156300 \t loss (ema): 0.048 \t Time elapsed: 1.450 hr\n",
      "Steps: 21820/156300 \t loss (ema): 0.061 \t Time elapsed: 1.457 hr\n",
      "Steps: 21883/156300 \t loss (ema): 0.054 \t Time elapsed: 1.461 hr\n",
      "Steps: 21983/156300 \t loss (ema): 0.053 \t Time elapsed: 1.468 hr\n",
      "Steps: 22083/156300 \t loss (ema): 0.056 \t Time elapsed: 1.474 hr\n",
      "Steps: 22183/156300 \t loss (ema): 0.053 \t Time elapsed: 1.481 hr\n",
      "Steps: 22283/156300 \t loss (ema): 0.051 \t Time elapsed: 1.488 hr\n",
      "Steps: 22383/156300 \t loss (ema): 0.052 \t Time elapsed: 1.494 hr\n",
      "Steps: 22483/156300 \t loss (ema): 0.057 \t Time elapsed: 1.501 hr\n",
      "Steps: 22583/156300 \t loss (ema): 0.054 \t Time elapsed: 1.508 hr\n",
      "Steps: 22683/156300 \t loss (ema): 0.053 \t Time elapsed: 1.514 hr\n",
      "Steps: 22783/156300 \t loss (ema): 0.061 \t Time elapsed: 1.521 hr\n",
      "Steps: 22883/156300 \t loss (ema): 0.065 \t Time elapsed: 1.528 hr\n",
      "Steps: 22983/156300 \t loss (ema): 0.054 \t Time elapsed: 1.534 hr\n",
      "Steps: 23083/156300 \t loss (ema): 0.049 \t Time elapsed: 1.541 hr\n",
      "Steps: 23183/156300 \t loss (ema): 0.058 \t Time elapsed: 1.548 hr\n",
      "Steps: 23283/156300 \t loss (ema): 0.056 \t Time elapsed: 1.554 hr\n",
      "Steps: 23383/156300 \t loss (ema): 0.050 \t Time elapsed: 1.561 hr\n",
      "Steps: 23446/156300 \t loss (ema): 0.058 \t Time elapsed: 1.565 hr\n",
      "Steps: 23546/156300 \t loss (ema): 0.051 \t Time elapsed: 1.572 hr\n",
      "Steps: 23646/156300 \t loss (ema): 0.048 \t Time elapsed: 1.579 hr\n",
      "Steps: 23746/156300 \t loss (ema): 0.052 \t Time elapsed: 1.585 hr\n",
      "Steps: 23846/156300 \t loss (ema): 0.048 \t Time elapsed: 1.592 hr\n",
      "Steps: 23946/156300 \t loss (ema): 0.057 \t Time elapsed: 1.599 hr\n",
      "Steps: 24046/156300 \t loss (ema): 0.058 \t Time elapsed: 1.605 hr\n",
      "Steps: 24146/156300 \t loss (ema): 0.055 \t Time elapsed: 1.612 hr\n",
      "Steps: 24246/156300 \t loss (ema): 0.045 \t Time elapsed: 1.619 hr\n",
      "Steps: 24346/156300 \t loss (ema): 0.054 \t Time elapsed: 1.625 hr\n",
      "Steps: 24446/156300 \t loss (ema): 0.053 \t Time elapsed: 1.632 hr\n",
      "Steps: 24546/156300 \t loss (ema): 0.046 \t Time elapsed: 1.639 hr\n",
      "Steps: 24646/156300 \t loss (ema): 0.065 \t Time elapsed: 1.645 hr\n",
      "Steps: 24746/156300 \t loss (ema): 0.056 \t Time elapsed: 1.652 hr\n",
      "Steps: 24846/156300 \t loss (ema): 0.057 \t Time elapsed: 1.659 hr\n",
      "Steps: 24946/156300 \t loss (ema): 0.055 \t Time elapsed: 1.665 hr\n",
      "Steps: 25009/156300 \t loss (ema): 0.047 \t Time elapsed: 1.670 hr\n",
      "Steps: 25109/156300 \t loss (ema): 0.047 \t Time elapsed: 1.676 hr\n",
      "Steps: 25209/156300 \t loss (ema): 0.055 \t Time elapsed: 1.683 hr\n",
      "Steps: 25309/156300 \t loss (ema): 0.062 \t Time elapsed: 1.690 hr\n",
      "Steps: 25409/156300 \t loss (ema): 0.051 \t Time elapsed: 1.696 hr\n",
      "Steps: 25509/156300 \t loss (ema): 0.058 \t Time elapsed: 1.703 hr\n",
      "Steps: 25609/156300 \t loss (ema): 0.051 \t Time elapsed: 1.710 hr\n",
      "Steps: 25709/156300 \t loss (ema): 0.056 \t Time elapsed: 1.717 hr\n",
      "Steps: 25809/156300 \t loss (ema): 0.050 \t Time elapsed: 1.723 hr\n",
      "Steps: 25909/156300 \t loss (ema): 0.061 \t Time elapsed: 1.730 hr\n",
      "Steps: 26009/156300 \t loss (ema): 0.050 \t Time elapsed: 1.737 hr\n",
      "Steps: 26109/156300 \t loss (ema): 0.055 \t Time elapsed: 1.743 hr\n",
      "Steps: 26209/156300 \t loss (ema): 0.052 \t Time elapsed: 1.750 hr\n",
      "Steps: 26309/156300 \t loss (ema): 0.060 \t Time elapsed: 1.757 hr\n",
      "Steps: 26409/156300 \t loss (ema): 0.048 \t Time elapsed: 1.763 hr\n",
      "Steps: 26509/156300 \t loss (ema): 0.048 \t Time elapsed: 1.770 hr\n",
      "Steps: 26572/156300 \t loss (ema): 0.057 \t Time elapsed: 1.774 hr\n",
      "Steps: 26672/156300 \t loss (ema): 0.050 \t Time elapsed: 1.781 hr\n",
      "Steps: 26772/156300 \t loss (ema): 0.052 \t Time elapsed: 1.787 hr\n",
      "Steps: 26872/156300 \t loss (ema): 0.058 \t Time elapsed: 1.794 hr\n",
      "Steps: 26972/156300 \t loss (ema): 0.052 \t Time elapsed: 1.801 hr\n",
      "Steps: 27072/156300 \t loss (ema): 0.053 \t Time elapsed: 1.807 hr\n",
      "Steps: 27172/156300 \t loss (ema): 0.054 \t Time elapsed: 1.814 hr\n",
      "Steps: 27272/156300 \t loss (ema): 0.054 \t Time elapsed: 1.821 hr\n",
      "Steps: 27372/156300 \t loss (ema): 0.055 \t Time elapsed: 1.827 hr\n",
      "Steps: 27472/156300 \t loss (ema): 0.059 \t Time elapsed: 1.834 hr\n",
      "Steps: 27572/156300 \t loss (ema): 0.053 \t Time elapsed: 1.841 hr\n",
      "Steps: 27672/156300 \t loss (ema): 0.052 \t Time elapsed: 1.847 hr\n",
      "Steps: 27772/156300 \t loss (ema): 0.046 \t Time elapsed: 1.854 hr\n",
      "Steps: 27872/156300 \t loss (ema): 0.057 \t Time elapsed: 1.861 hr\n",
      "Steps: 27972/156300 \t loss (ema): 0.053 \t Time elapsed: 1.867 hr\n",
      "Steps: 28072/156300 \t loss (ema): 0.051 \t Time elapsed: 1.874 hr\n",
      "Steps: 28135/156300 \t loss (ema): 0.063 \t Time elapsed: 1.878 hr\n",
      "Steps: 28235/156300 \t loss (ema): 0.054 \t Time elapsed: 1.885 hr\n",
      "Steps: 28335/156300 \t loss (ema): 0.045 \t Time elapsed: 1.891 hr\n",
      "Steps: 28435/156300 \t loss (ema): 0.055 \t Time elapsed: 1.898 hr\n",
      "Steps: 28535/156300 \t loss (ema): 0.049 \t Time elapsed: 1.905 hr\n",
      "Steps: 28635/156300 \t loss (ema): 0.052 \t Time elapsed: 1.912 hr\n",
      "Steps: 28735/156300 \t loss (ema): 0.059 \t Time elapsed: 1.918 hr\n",
      "Steps: 28835/156300 \t loss (ema): 0.059 \t Time elapsed: 1.925 hr\n",
      "Steps: 28935/156300 \t loss (ema): 0.057 \t Time elapsed: 1.932 hr\n",
      "Steps: 29035/156300 \t loss (ema): 0.055 \t Time elapsed: 1.938 hr\n",
      "Steps: 29135/156300 \t loss (ema): 0.056 \t Time elapsed: 1.945 hr\n",
      "Steps: 29235/156300 \t loss (ema): 0.048 \t Time elapsed: 1.952 hr\n",
      "Steps: 29335/156300 \t loss (ema): 0.048 \t Time elapsed: 1.958 hr\n",
      "Steps: 29435/156300 \t loss (ema): 0.051 \t Time elapsed: 1.965 hr\n",
      "Steps: 29535/156300 \t loss (ema): 0.056 \t Time elapsed: 1.972 hr\n",
      "Steps: 29635/156300 \t loss (ema): 0.051 \t Time elapsed: 1.978 hr\n",
      "Steps: 29698/156300 \t loss (ema): 0.058 \t Time elapsed: 1.983 hr\n",
      "Steps: 29798/156300 \t loss (ema): 0.055 \t Time elapsed: 1.989 hr\n",
      "Steps: 29898/156300 \t loss (ema): 0.051 \t Time elapsed: 1.996 hr\n",
      "Steps: 29998/156300 \t loss (ema): 0.057 \t Time elapsed: 2.003 hr\n",
      "Steps: 30098/156300 \t loss (ema): 0.056 \t Time elapsed: 2.009 hr\n",
      "Steps: 30198/156300 \t loss (ema): 0.055 \t Time elapsed: 2.016 hr\n",
      "Steps: 30298/156300 \t loss (ema): 0.058 \t Time elapsed: 2.023 hr\n",
      "Steps: 30398/156300 \t loss (ema): 0.053 \t Time elapsed: 2.029 hr\n",
      "Steps: 30498/156300 \t loss (ema): 0.053 \t Time elapsed: 2.036 hr\n",
      "Steps: 30598/156300 \t loss (ema): 0.057 \t Time elapsed: 2.043 hr\n",
      "Steps: 30698/156300 \t loss (ema): 0.058 \t Time elapsed: 2.050 hr\n",
      "Steps: 30798/156300 \t loss (ema): 0.053 \t Time elapsed: 2.056 hr\n",
      "Steps: 30898/156300 \t loss (ema): 0.043 \t Time elapsed: 2.063 hr\n",
      "Steps: 30998/156300 \t loss (ema): 0.055 \t Time elapsed: 2.070 hr\n",
      "Steps: 31098/156300 \t loss (ema): 0.054 \t Time elapsed: 2.076 hr\n",
      "Steps: 31198/156300 \t loss (ema): 0.057 \t Time elapsed: 2.083 hr\n",
      "Steps: 31261/156300 \t loss (ema): 0.049 \t Time elapsed: 2.087 hr\n",
      "Steps: 31361/156300 \t loss (ema): 0.052 \t Time elapsed: 2.094 hr\n",
      "Steps: 31461/156300 \t loss (ema): 0.058 \t Time elapsed: 2.101 hr\n",
      "Steps: 31561/156300 \t loss (ema): 0.054 \t Time elapsed: 2.107 hr\n",
      "Steps: 31661/156300 \t loss (ema): 0.061 \t Time elapsed: 2.114 hr\n",
      "Steps: 31761/156300 \t loss (ema): 0.047 \t Time elapsed: 2.121 hr\n",
      "Steps: 31861/156300 \t loss (ema): 0.053 \t Time elapsed: 2.127 hr\n",
      "Steps: 31961/156300 \t loss (ema): 0.045 \t Time elapsed: 2.134 hr\n",
      "Steps: 32061/156300 \t loss (ema): 0.045 \t Time elapsed: 2.141 hr\n",
      "Steps: 32161/156300 \t loss (ema): 0.042 \t Time elapsed: 2.147 hr\n",
      "Steps: 32261/156300 \t loss (ema): 0.052 \t Time elapsed: 2.154 hr\n",
      "Steps: 32361/156300 \t loss (ema): 0.056 \t Time elapsed: 2.160 hr\n",
      "Steps: 32461/156300 \t loss (ema): 0.058 \t Time elapsed: 2.167 hr\n",
      "Steps: 32561/156300 \t loss (ema): 0.059 \t Time elapsed: 2.174 hr\n",
      "Steps: 32661/156300 \t loss (ema): 0.061 \t Time elapsed: 2.180 hr\n",
      "Steps: 32761/156300 \t loss (ema): 0.048 \t Time elapsed: 2.187 hr\n",
      "Epoch 20 completed\n",
      "Steps: 32824/156300 \t loss (ema): 0.053 \t Time elapsed: 2.191 hr\n",
      "Steps: 32924/156300 \t loss (ema): 0.052 \t Time elapsed: 2.198 hr\n",
      "Steps: 33024/156300 \t loss (ema): 0.056 \t Time elapsed: 2.205 hr\n",
      "Steps: 33124/156300 \t loss (ema): 0.053 \t Time elapsed: 2.211 hr\n",
      "Steps: 33224/156300 \t loss (ema): 0.047 \t Time elapsed: 2.218 hr\n",
      "Steps: 33324/156300 \t loss (ema): 0.053 \t Time elapsed: 2.225 hr\n",
      "Steps: 33424/156300 \t loss (ema): 0.048 \t Time elapsed: 2.231 hr\n",
      "Steps: 33524/156300 \t loss (ema): 0.056 \t Time elapsed: 2.238 hr\n",
      "Steps: 33624/156300 \t loss (ema): 0.051 \t Time elapsed: 2.245 hr\n",
      "Steps: 33724/156300 \t loss (ema): 0.055 \t Time elapsed: 2.251 hr\n",
      "Steps: 33824/156300 \t loss (ema): 0.055 \t Time elapsed: 2.258 hr\n",
      "Steps: 33924/156300 \t loss (ema): 0.045 \t Time elapsed: 2.265 hr\n",
      "Steps: 34024/156300 \t loss (ema): 0.062 \t Time elapsed: 2.272 hr\n",
      "Steps: 34124/156300 \t loss (ema): 0.056 \t Time elapsed: 2.278 hr\n",
      "Steps: 34224/156300 \t loss (ema): 0.056 \t Time elapsed: 2.285 hr\n",
      "Steps: 34324/156300 \t loss (ema): 0.047 \t Time elapsed: 2.292 hr\n",
      "Steps: 34387/156300 \t loss (ema): 0.052 \t Time elapsed: 2.296 hr\n",
      "Steps: 34487/156300 \t loss (ema): 0.061 \t Time elapsed: 2.302 hr\n",
      "Steps: 34587/156300 \t loss (ema): 0.055 \t Time elapsed: 2.309 hr\n",
      "Steps: 34687/156300 \t loss (ema): 0.055 \t Time elapsed: 2.316 hr\n",
      "Steps: 34787/156300 \t loss (ema): 0.067 \t Time elapsed: 2.323 hr\n",
      "Steps: 34887/156300 \t loss (ema): 0.059 \t Time elapsed: 2.329 hr\n",
      "Steps: 34987/156300 \t loss (ema): 0.051 \t Time elapsed: 2.336 hr\n",
      "Steps: 35087/156300 \t loss (ema): 0.053 \t Time elapsed: 2.343 hr\n",
      "Steps: 35187/156300 \t loss (ema): 0.051 \t Time elapsed: 2.349 hr\n",
      "Steps: 35287/156300 \t loss (ema): 0.056 \t Time elapsed: 2.356 hr\n",
      "Steps: 35387/156300 \t loss (ema): 0.051 \t Time elapsed: 2.363 hr\n",
      "Steps: 35487/156300 \t loss (ema): 0.056 \t Time elapsed: 2.369 hr\n",
      "Steps: 35587/156300 \t loss (ema): 0.062 \t Time elapsed: 2.376 hr\n",
      "Steps: 35687/156300 \t loss (ema): 0.059 \t Time elapsed: 2.383 hr\n",
      "Steps: 35787/156300 \t loss (ema): 0.055 \t Time elapsed: 2.389 hr\n",
      "Steps: 35887/156300 \t loss (ema): 0.051 \t Time elapsed: 2.396 hr\n",
      "Steps: 35950/156300 \t loss (ema): 0.055 \t Time elapsed: 2.400 hr\n",
      "Steps: 36050/156300 \t loss (ema): 0.057 \t Time elapsed: 2.407 hr\n",
      "Steps: 36150/156300 \t loss (ema): 0.060 \t Time elapsed: 2.414 hr\n",
      "Steps: 36250/156300 \t loss (ema): 0.059 \t Time elapsed: 2.420 hr\n",
      "Steps: 36350/156300 \t loss (ema): 0.053 \t Time elapsed: 2.427 hr\n",
      "Steps: 36450/156300 \t loss (ema): 0.056 \t Time elapsed: 2.434 hr\n",
      "Steps: 36550/156300 \t loss (ema): 0.056 \t Time elapsed: 2.440 hr\n",
      "Steps: 36650/156300 \t loss (ema): 0.044 \t Time elapsed: 2.447 hr\n",
      "Steps: 36750/156300 \t loss (ema): 0.050 \t Time elapsed: 2.454 hr\n",
      "Steps: 36850/156300 \t loss (ema): 0.052 \t Time elapsed: 2.460 hr\n",
      "Steps: 36950/156300 \t loss (ema): 0.070 \t Time elapsed: 2.467 hr\n",
      "Steps: 37050/156300 \t loss (ema): 0.065 \t Time elapsed: 2.474 hr\n",
      "Steps: 37150/156300 \t loss (ema): 0.046 \t Time elapsed: 2.480 hr\n",
      "Steps: 37250/156300 \t loss (ema): 0.056 \t Time elapsed: 2.487 hr\n",
      "Steps: 37350/156300 \t loss (ema): 0.053 \t Time elapsed: 2.494 hr\n",
      "Steps: 37450/156300 \t loss (ema): 0.055 \t Time elapsed: 2.500 hr\n",
      "Steps: 37513/156300 \t loss (ema): 0.049 \t Time elapsed: 2.505 hr\n",
      "Steps: 37613/156300 \t loss (ema): 0.060 \t Time elapsed: 2.511 hr\n",
      "Steps: 37713/156300 \t loss (ema): 0.050 \t Time elapsed: 2.518 hr\n",
      "Steps: 37813/156300 \t loss (ema): 0.048 \t Time elapsed: 2.525 hr\n",
      "Steps: 37913/156300 \t loss (ema): 0.049 \t Time elapsed: 2.531 hr\n",
      "Steps: 38013/156300 \t loss (ema): 0.054 \t Time elapsed: 2.538 hr\n",
      "Steps: 38113/156300 \t loss (ema): 0.067 \t Time elapsed: 2.544 hr\n",
      "Steps: 38213/156300 \t loss (ema): 0.055 \t Time elapsed: 2.551 hr\n",
      "Steps: 38313/156300 \t loss (ema): 0.047 \t Time elapsed: 2.558 hr\n",
      "Steps: 38413/156300 \t loss (ema): 0.056 \t Time elapsed: 2.564 hr\n",
      "Steps: 38513/156300 \t loss (ema): 0.048 \t Time elapsed: 2.571 hr\n",
      "Steps: 38613/156300 \t loss (ema): 0.057 \t Time elapsed: 2.578 hr\n",
      "Steps: 38713/156300 \t loss (ema): 0.059 \t Time elapsed: 2.584 hr\n",
      "Steps: 38813/156300 \t loss (ema): 0.057 \t Time elapsed: 2.591 hr\n",
      "Steps: 38913/156300 \t loss (ema): 0.059 \t Time elapsed: 2.598 hr\n",
      "Steps: 39013/156300 \t loss (ema): 0.067 \t Time elapsed: 2.604 hr\n",
      "Steps: 39076/156300 \t loss (ema): 0.047 \t Time elapsed: 2.609 hr\n",
      "Steps: 39176/156300 \t loss (ema): 0.057 \t Time elapsed: 2.615 hr\n",
      "Steps: 39276/156300 \t loss (ema): 0.052 \t Time elapsed: 2.622 hr\n",
      "Steps: 39376/156300 \t loss (ema): 0.052 \t Time elapsed: 2.629 hr\n",
      "Steps: 39476/156300 \t loss (ema): 0.054 \t Time elapsed: 2.635 hr\n",
      "Steps: 39576/156300 \t loss (ema): 0.050 \t Time elapsed: 2.642 hr\n",
      "Steps: 39676/156300 \t loss (ema): 0.063 \t Time elapsed: 2.649 hr\n",
      "Steps: 39776/156300 \t loss (ema): 0.050 \t Time elapsed: 2.655 hr\n",
      "Steps: 39876/156300 \t loss (ema): 0.057 \t Time elapsed: 2.662 hr\n",
      "Steps: 39976/156300 \t loss (ema): 0.054 \t Time elapsed: 2.669 hr\n",
      "Steps: 40076/156300 \t loss (ema): 0.049 \t Time elapsed: 2.675 hr\n",
      "Steps: 40176/156300 \t loss (ema): 0.060 \t Time elapsed: 2.682 hr\n",
      "Steps: 40276/156300 \t loss (ema): 0.054 \t Time elapsed: 2.689 hr\n",
      "Steps: 40376/156300 \t loss (ema): 0.048 \t Time elapsed: 2.696 hr\n",
      "Steps: 40476/156300 \t loss (ema): 0.044 \t Time elapsed: 2.702 hr\n",
      "Steps: 40576/156300 \t loss (ema): 0.055 \t Time elapsed: 2.709 hr\n",
      "Steps: 40639/156300 \t loss (ema): 0.059 \t Time elapsed: 2.713 hr\n",
      "Steps: 40739/156300 \t loss (ema): 0.051 \t Time elapsed: 2.720 hr\n",
      "Steps: 40839/156300 \t loss (ema): 0.053 \t Time elapsed: 2.727 hr\n",
      "Steps: 40939/156300 \t loss (ema): 0.060 \t Time elapsed: 2.733 hr\n",
      "Steps: 41039/156300 \t loss (ema): 0.052 \t Time elapsed: 2.740 hr\n",
      "Steps: 41139/156300 \t loss (ema): 0.048 \t Time elapsed: 2.747 hr\n",
      "Steps: 41239/156300 \t loss (ema): 0.055 \t Time elapsed: 2.753 hr\n",
      "Steps: 41339/156300 \t loss (ema): 0.056 \t Time elapsed: 2.760 hr\n",
      "Steps: 41439/156300 \t loss (ema): 0.058 \t Time elapsed: 2.767 hr\n",
      "Steps: 41539/156300 \t loss (ema): 0.060 \t Time elapsed: 2.773 hr\n",
      "Steps: 41639/156300 \t loss (ema): 0.057 \t Time elapsed: 2.780 hr\n",
      "Steps: 41739/156300 \t loss (ema): 0.047 \t Time elapsed: 2.787 hr\n",
      "Steps: 41839/156300 \t loss (ema): 0.051 \t Time elapsed: 2.794 hr\n",
      "Steps: 41939/156300 \t loss (ema): 0.049 \t Time elapsed: 2.800 hr\n",
      "Steps: 42039/156300 \t loss (ema): 0.058 \t Time elapsed: 2.807 hr\n",
      "Steps: 42139/156300 \t loss (ema): 0.067 \t Time elapsed: 2.814 hr\n",
      "Steps: 42202/156300 \t loss (ema): 0.054 \t Time elapsed: 2.818 hr\n",
      "Steps: 42302/156300 \t loss (ema): 0.060 \t Time elapsed: 2.824 hr\n",
      "Steps: 42402/156300 \t loss (ema): 0.055 \t Time elapsed: 2.831 hr\n",
      "Steps: 42502/156300 \t loss (ema): 0.049 \t Time elapsed: 2.838 hr\n",
      "Steps: 42602/156300 \t loss (ema): 0.044 \t Time elapsed: 2.844 hr\n",
      "Steps: 42702/156300 \t loss (ema): 0.052 \t Time elapsed: 2.851 hr\n",
      "Steps: 42802/156300 \t loss (ema): 0.055 \t Time elapsed: 2.858 hr\n",
      "Steps: 42902/156300 \t loss (ema): 0.052 \t Time elapsed: 2.864 hr\n",
      "Steps: 43002/156300 \t loss (ema): 0.048 \t Time elapsed: 2.871 hr\n",
      "Steps: 43102/156300 \t loss (ema): 0.045 \t Time elapsed: 2.878 hr\n",
      "Steps: 43202/156300 \t loss (ema): 0.047 \t Time elapsed: 2.884 hr\n",
      "Steps: 43302/156300 \t loss (ema): 0.051 \t Time elapsed: 2.891 hr\n",
      "Steps: 43402/156300 \t loss (ema): 0.056 \t Time elapsed: 2.897 hr\n",
      "Steps: 43502/156300 \t loss (ema): 0.053 \t Time elapsed: 2.904 hr\n",
      "Steps: 43602/156300 \t loss (ema): 0.058 \t Time elapsed: 2.911 hr\n",
      "Steps: 43702/156300 \t loss (ema): 0.053 \t Time elapsed: 2.917 hr\n",
      "Steps: 43765/156300 \t loss (ema): 0.048 \t Time elapsed: 2.922 hr\n",
      "Steps: 43865/156300 \t loss (ema): 0.054 \t Time elapsed: 2.928 hr\n",
      "Steps: 43965/156300 \t loss (ema): 0.047 \t Time elapsed: 2.935 hr\n",
      "Steps: 44065/156300 \t loss (ema): 0.057 \t Time elapsed: 2.942 hr\n",
      "Steps: 44165/156300 \t loss (ema): 0.052 \t Time elapsed: 2.948 hr\n",
      "Steps: 44265/156300 \t loss (ema): 0.053 \t Time elapsed: 2.955 hr\n",
      "Steps: 44365/156300 \t loss (ema): 0.048 \t Time elapsed: 2.962 hr\n",
      "Steps: 44465/156300 \t loss (ema): 0.054 \t Time elapsed: 2.968 hr\n",
      "Steps: 44565/156300 \t loss (ema): 0.051 \t Time elapsed: 2.975 hr\n",
      "Steps: 44665/156300 \t loss (ema): 0.055 \t Time elapsed: 2.982 hr\n",
      "Steps: 44765/156300 \t loss (ema): 0.058 \t Time elapsed: 2.988 hr\n",
      "Steps: 44865/156300 \t loss (ema): 0.054 \t Time elapsed: 2.995 hr\n",
      "Steps: 44965/156300 \t loss (ema): 0.057 \t Time elapsed: 3.002 hr\n",
      "Steps: 45065/156300 \t loss (ema): 0.058 \t Time elapsed: 3.008 hr\n",
      "Steps: 45165/156300 \t loss (ema): 0.045 \t Time elapsed: 3.015 hr\n",
      "Steps: 45265/156300 \t loss (ema): 0.055 \t Time elapsed: 3.022 hr\n",
      "Steps: 45328/156300 \t loss (ema): 0.056 \t Time elapsed: 3.026 hr\n",
      "Steps: 45428/156300 \t loss (ema): 0.054 \t Time elapsed: 3.033 hr\n",
      "Steps: 45528/156300 \t loss (ema): 0.046 \t Time elapsed: 3.039 hr\n",
      "Steps: 45628/156300 \t loss (ema): 0.055 \t Time elapsed: 3.046 hr\n",
      "Steps: 45728/156300 \t loss (ema): 0.048 \t Time elapsed: 3.053 hr\n",
      "Steps: 45828/156300 \t loss (ema): 0.061 \t Time elapsed: 3.059 hr\n",
      "Steps: 45928/156300 \t loss (ema): 0.058 \t Time elapsed: 3.066 hr\n",
      "Steps: 46028/156300 \t loss (ema): 0.048 \t Time elapsed: 3.073 hr\n",
      "Steps: 46128/156300 \t loss (ema): 0.052 \t Time elapsed: 3.080 hr\n",
      "Steps: 46228/156300 \t loss (ema): 0.056 \t Time elapsed: 3.086 hr\n",
      "Steps: 46328/156300 \t loss (ema): 0.049 \t Time elapsed: 3.093 hr\n",
      "Steps: 46428/156300 \t loss (ema): 0.050 \t Time elapsed: 3.100 hr\n",
      "Steps: 46528/156300 \t loss (ema): 0.053 \t Time elapsed: 3.106 hr\n",
      "Steps: 46628/156300 \t loss (ema): 0.049 \t Time elapsed: 3.113 hr\n",
      "Steps: 46728/156300 \t loss (ema): 0.052 \t Time elapsed: 3.120 hr\n",
      "Steps: 46828/156300 \t loss (ema): 0.047 \t Time elapsed: 3.126 hr\n",
      "Steps: 46891/156300 \t loss (ema): 0.049 \t Time elapsed: 3.131 hr\n",
      "Steps: 46991/156300 \t loss (ema): 0.063 \t Time elapsed: 3.137 hr\n",
      "Steps: 47091/156300 \t loss (ema): 0.056 \t Time elapsed: 3.144 hr\n",
      "Steps: 47191/156300 \t loss (ema): 0.047 \t Time elapsed: 3.151 hr\n",
      "Steps: 47291/156300 \t loss (ema): 0.054 \t Time elapsed: 3.157 hr\n",
      "Steps: 47391/156300 \t loss (ema): 0.049 \t Time elapsed: 3.164 hr\n",
      "Steps: 47491/156300 \t loss (ema): 0.058 \t Time elapsed: 3.171 hr\n",
      "Steps: 47591/156300 \t loss (ema): 0.057 \t Time elapsed: 3.177 hr\n",
      "Steps: 47691/156300 \t loss (ema): 0.066 \t Time elapsed: 3.184 hr\n",
      "Steps: 47791/156300 \t loss (ema): 0.059 \t Time elapsed: 3.191 hr\n",
      "Steps: 47891/156300 \t loss (ema): 0.059 \t Time elapsed: 3.197 hr\n",
      "Steps: 47991/156300 \t loss (ema): 0.056 \t Time elapsed: 3.204 hr\n",
      "Steps: 48091/156300 \t loss (ema): 0.054 \t Time elapsed: 3.211 hr\n",
      "Steps: 48191/156300 \t loss (ema): 0.055 \t Time elapsed: 3.217 hr\n",
      "Steps: 48291/156300 \t loss (ema): 0.048 \t Time elapsed: 3.224 hr\n",
      "Steps: 48391/156300 \t loss (ema): 0.051 \t Time elapsed: 3.231 hr\n",
      "Epoch 30 completed\n",
      "Steps: 48454/156300 \t loss (ema): 0.052 \t Time elapsed: 3.235 hr\n",
      "Steps: 48554/156300 \t loss (ema): 0.051 \t Time elapsed: 3.242 hr\n",
      "Steps: 48654/156300 \t loss (ema): 0.063 \t Time elapsed: 3.248 hr\n",
      "Steps: 48754/156300 \t loss (ema): 0.053 \t Time elapsed: 3.255 hr\n",
      "Steps: 48854/156300 \t loss (ema): 0.058 \t Time elapsed: 3.262 hr\n",
      "Steps: 48954/156300 \t loss (ema): 0.055 \t Time elapsed: 3.268 hr\n",
      "Steps: 49054/156300 \t loss (ema): 0.058 \t Time elapsed: 3.275 hr\n",
      "Steps: 49154/156300 \t loss (ema): 0.048 \t Time elapsed: 3.282 hr\n",
      "Steps: 49254/156300 \t loss (ema): 0.056 \t Time elapsed: 3.288 hr\n",
      "Steps: 49354/156300 \t loss (ema): 0.050 \t Time elapsed: 3.295 hr\n",
      "Steps: 49454/156300 \t loss (ema): 0.051 \t Time elapsed: 3.302 hr\n",
      "Steps: 49554/156300 \t loss (ema): 0.057 \t Time elapsed: 3.308 hr\n",
      "Steps: 49654/156300 \t loss (ema): 0.049 \t Time elapsed: 3.315 hr\n",
      "Steps: 49754/156300 \t loss (ema): 0.052 \t Time elapsed: 3.322 hr\n",
      "Steps: 49854/156300 \t loss (ema): 0.050 \t Time elapsed: 3.328 hr\n",
      "Steps: 49954/156300 \t loss (ema): 0.056 \t Time elapsed: 3.335 hr\n",
      "Steps: 50017/156300 \t loss (ema): 0.049 \t Time elapsed: 3.339 hr\n",
      "Steps: 50117/156300 \t loss (ema): 0.055 \t Time elapsed: 3.346 hr\n",
      "Steps: 50217/156300 \t loss (ema): 0.060 \t Time elapsed: 3.353 hr\n",
      "Steps: 50317/156300 \t loss (ema): 0.057 \t Time elapsed: 3.359 hr\n",
      "Steps: 50417/156300 \t loss (ema): 0.051 \t Time elapsed: 3.366 hr\n",
      "Steps: 50517/156300 \t loss (ema): 0.050 \t Time elapsed: 3.373 hr\n",
      "Steps: 50617/156300 \t loss (ema): 0.053 \t Time elapsed: 3.379 hr\n",
      "Steps: 50717/156300 \t loss (ema): 0.054 \t Time elapsed: 3.386 hr\n",
      "Steps: 50817/156300 \t loss (ema): 0.051 \t Time elapsed: 3.393 hr\n",
      "Steps: 50917/156300 \t loss (ema): 0.056 \t Time elapsed: 3.400 hr\n",
      "Steps: 51017/156300 \t loss (ema): 0.054 \t Time elapsed: 3.406 hr\n",
      "Steps: 51117/156300 \t loss (ema): 0.045 \t Time elapsed: 3.413 hr\n",
      "Steps: 51217/156300 \t loss (ema): 0.053 \t Time elapsed: 3.420 hr\n",
      "Steps: 51317/156300 \t loss (ema): 0.051 \t Time elapsed: 3.426 hr\n",
      "Steps: 51417/156300 \t loss (ema): 0.053 \t Time elapsed: 3.433 hr\n",
      "Steps: 51517/156300 \t loss (ema): 0.056 \t Time elapsed: 3.440 hr\n",
      "Steps: 51580/156300 \t loss (ema): 0.056 \t Time elapsed: 3.444 hr\n",
      "Steps: 51680/156300 \t loss (ema): 0.048 \t Time elapsed: 3.451 hr\n",
      "Steps: 51780/156300 \t loss (ema): 0.055 \t Time elapsed: 3.457 hr\n",
      "Steps: 51880/156300 \t loss (ema): 0.050 \t Time elapsed: 3.464 hr\n",
      "Steps: 51980/156300 \t loss (ema): 0.052 \t Time elapsed: 3.471 hr\n",
      "Steps: 52080/156300 \t loss (ema): 0.056 \t Time elapsed: 3.477 hr\n",
      "Steps: 52180/156300 \t loss (ema): 0.053 \t Time elapsed: 3.484 hr\n",
      "Steps: 52280/156300 \t loss (ema): 0.052 \t Time elapsed: 3.491 hr\n",
      "Steps: 52380/156300 \t loss (ema): 0.053 \t Time elapsed: 3.497 hr\n",
      "Steps: 52480/156300 \t loss (ema): 0.047 \t Time elapsed: 3.504 hr\n",
      "Steps: 52580/156300 \t loss (ema): 0.056 \t Time elapsed: 3.511 hr\n",
      "Steps: 52680/156300 \t loss (ema): 0.063 \t Time elapsed: 3.518 hr\n",
      "Steps: 52780/156300 \t loss (ema): 0.053 \t Time elapsed: 3.524 hr\n",
      "Steps: 52880/156300 \t loss (ema): 0.052 \t Time elapsed: 3.531 hr\n",
      "Steps: 52980/156300 \t loss (ema): 0.056 \t Time elapsed: 3.538 hr\n",
      "Steps: 53080/156300 \t loss (ema): 0.050 \t Time elapsed: 3.544 hr\n",
      "Steps: 53143/156300 \t loss (ema): 0.062 \t Time elapsed: 3.548 hr\n",
      "Steps: 53243/156300 \t loss (ema): 0.051 \t Time elapsed: 3.555 hr\n",
      "Steps: 53343/156300 \t loss (ema): 0.060 \t Time elapsed: 3.562 hr\n",
      "Steps: 53443/156300 \t loss (ema): 0.053 \t Time elapsed: 3.568 hr\n",
      "Steps: 53543/156300 \t loss (ema): 0.049 \t Time elapsed: 3.575 hr\n",
      "Steps: 53643/156300 \t loss (ema): 0.068 \t Time elapsed: 3.582 hr\n",
      "Steps: 53743/156300 \t loss (ema): 0.056 \t Time elapsed: 3.588 hr\n",
      "Steps: 53843/156300 \t loss (ema): 0.041 \t Time elapsed: 3.595 hr\n",
      "Steps: 53943/156300 \t loss (ema): 0.056 \t Time elapsed: 3.602 hr\n",
      "Steps: 54043/156300 \t loss (ema): 0.060 \t Time elapsed: 3.608 hr\n",
      "Steps: 54143/156300 \t loss (ema): 0.051 \t Time elapsed: 3.615 hr\n",
      "Steps: 54243/156300 \t loss (ema): 0.050 \t Time elapsed: 3.622 hr\n",
      "Steps: 54343/156300 \t loss (ema): 0.052 \t Time elapsed: 3.628 hr\n",
      "Steps: 54443/156300 \t loss (ema): 0.059 \t Time elapsed: 3.635 hr\n",
      "Steps: 54543/156300 \t loss (ema): 0.053 \t Time elapsed: 3.642 hr\n",
      "Steps: 54643/156300 \t loss (ema): 0.054 \t Time elapsed: 3.648 hr\n",
      "Steps: 54706/156300 \t loss (ema): 0.055 \t Time elapsed: 3.652 hr\n",
      "Steps: 54806/156300 \t loss (ema): 0.051 \t Time elapsed: 3.659 hr\n",
      "Steps: 54906/156300 \t loss (ema): 0.063 \t Time elapsed: 3.666 hr\n",
      "Steps: 55006/156300 \t loss (ema): 0.058 \t Time elapsed: 3.672 hr\n",
      "Steps: 55106/156300 \t loss (ema): 0.042 \t Time elapsed: 3.679 hr\n",
      "Steps: 55206/156300 \t loss (ema): 0.051 \t Time elapsed: 3.686 hr\n",
      "Steps: 55306/156300 \t loss (ema): 0.062 \t Time elapsed: 3.693 hr\n",
      "Steps: 55406/156300 \t loss (ema): 0.064 \t Time elapsed: 3.699 hr\n",
      "Steps: 55506/156300 \t loss (ema): 0.048 \t Time elapsed: 3.706 hr\n",
      "Steps: 55606/156300 \t loss (ema): 0.055 \t Time elapsed: 3.713 hr\n",
      "Steps: 55706/156300 \t loss (ema): 0.052 \t Time elapsed: 3.719 hr\n",
      "Steps: 55806/156300 \t loss (ema): 0.045 \t Time elapsed: 3.726 hr\n",
      "Steps: 55906/156300 \t loss (ema): 0.049 \t Time elapsed: 3.733 hr\n",
      "Steps: 56006/156300 \t loss (ema): 0.046 \t Time elapsed: 3.739 hr\n",
      "Steps: 56106/156300 \t loss (ema): 0.056 \t Time elapsed: 3.746 hr\n",
      "Steps: 56206/156300 \t loss (ema): 0.054 \t Time elapsed: 3.753 hr\n",
      "Steps: 56269/156300 \t loss (ema): 0.055 \t Time elapsed: 3.757 hr\n",
      "Steps: 56369/156300 \t loss (ema): 0.056 \t Time elapsed: 3.764 hr\n",
      "Steps: 56469/156300 \t loss (ema): 0.053 \t Time elapsed: 3.770 hr\n",
      "Steps: 56569/156300 \t loss (ema): 0.046 \t Time elapsed: 3.777 hr\n",
      "Steps: 56669/156300 \t loss (ema): 0.055 \t Time elapsed: 3.784 hr\n",
      "Steps: 56769/156300 \t loss (ema): 0.052 \t Time elapsed: 3.790 hr\n",
      "Steps: 56869/156300 \t loss (ema): 0.059 \t Time elapsed: 3.797 hr\n",
      "Steps: 56969/156300 \t loss (ema): 0.056 \t Time elapsed: 3.804 hr\n",
      "Steps: 57069/156300 \t loss (ema): 0.060 \t Time elapsed: 3.811 hr\n",
      "Steps: 57169/156300 \t loss (ema): 0.054 \t Time elapsed: 3.817 hr\n",
      "Steps: 57269/156300 \t loss (ema): 0.052 \t Time elapsed: 3.824 hr\n",
      "Steps: 57369/156300 \t loss (ema): 0.065 \t Time elapsed: 3.831 hr\n",
      "Steps: 57469/156300 \t loss (ema): 0.050 \t Time elapsed: 3.837 hr\n",
      "Steps: 57569/156300 \t loss (ema): 0.060 \t Time elapsed: 3.844 hr\n",
      "Steps: 57669/156300 \t loss (ema): 0.058 \t Time elapsed: 3.851 hr\n",
      "Steps: 57769/156300 \t loss (ema): 0.057 \t Time elapsed: 3.857 hr\n",
      "Steps: 57832/156300 \t loss (ema): 0.046 \t Time elapsed: 3.862 hr\n",
      "Steps: 57932/156300 \t loss (ema): 0.047 \t Time elapsed: 3.868 hr\n",
      "Steps: 58032/156300 \t loss (ema): 0.059 \t Time elapsed: 3.875 hr\n",
      "Steps: 58132/156300 \t loss (ema): 0.051 \t Time elapsed: 3.882 hr\n",
      "Steps: 58232/156300 \t loss (ema): 0.049 \t Time elapsed: 3.888 hr\n",
      "Steps: 58332/156300 \t loss (ema): 0.049 \t Time elapsed: 3.895 hr\n",
      "Steps: 58432/156300 \t loss (ema): 0.057 \t Time elapsed: 3.902 hr\n",
      "Steps: 58532/156300 \t loss (ema): 0.060 \t Time elapsed: 3.908 hr\n",
      "Steps: 58632/156300 \t loss (ema): 0.049 \t Time elapsed: 3.915 hr\n",
      "Steps: 58732/156300 \t loss (ema): 0.055 \t Time elapsed: 3.922 hr\n",
      "Steps: 58832/156300 \t loss (ema): 0.068 \t Time elapsed: 3.928 hr\n",
      "Steps: 58932/156300 \t loss (ema): 0.059 \t Time elapsed: 3.935 hr\n",
      "Steps: 59032/156300 \t loss (ema): 0.050 \t Time elapsed: 3.942 hr\n",
      "Steps: 59132/156300 \t loss (ema): 0.053 \t Time elapsed: 3.948 hr\n",
      "Steps: 59232/156300 \t loss (ema): 0.051 \t Time elapsed: 3.955 hr\n",
      "Steps: 59332/156300 \t loss (ema): 0.049 \t Time elapsed: 3.961 hr\n",
      "Steps: 59395/156300 \t loss (ema): 0.055 \t Time elapsed: 3.966 hr\n",
      "Steps: 59495/156300 \t loss (ema): 0.055 \t Time elapsed: 3.972 hr\n",
      "Steps: 59595/156300 \t loss (ema): 0.054 \t Time elapsed: 3.979 hr\n",
      "Steps: 59695/156300 \t loss (ema): 0.063 \t Time elapsed: 3.986 hr\n",
      "Steps: 59795/156300 \t loss (ema): 0.046 \t Time elapsed: 3.992 hr\n",
      "Steps: 59895/156300 \t loss (ema): 0.045 \t Time elapsed: 3.999 hr\n",
      "Steps: 59995/156300 \t loss (ema): 0.051 \t Time elapsed: 4.006 hr\n",
      "Steps: 60095/156300 \t loss (ema): 0.056 \t Time elapsed: 4.012 hr\n",
      "Steps: 60195/156300 \t loss (ema): 0.057 \t Time elapsed: 4.019 hr\n",
      "Steps: 60295/156300 \t loss (ema): 0.057 \t Time elapsed: 4.026 hr\n",
      "Steps: 60395/156300 \t loss (ema): 0.052 \t Time elapsed: 4.032 hr\n",
      "Steps: 60495/156300 \t loss (ema): 0.050 \t Time elapsed: 4.039 hr\n",
      "Steps: 60595/156300 \t loss (ema): 0.051 \t Time elapsed: 4.046 hr\n",
      "Steps: 60695/156300 \t loss (ema): 0.050 \t Time elapsed: 4.052 hr\n",
      "Steps: 60795/156300 \t loss (ema): 0.054 \t Time elapsed: 4.059 hr\n",
      "Steps: 60895/156300 \t loss (ema): 0.057 \t Time elapsed: 4.066 hr\n",
      "Steps: 60958/156300 \t loss (ema): 0.056 \t Time elapsed: 4.070 hr\n",
      "Steps: 61058/156300 \t loss (ema): 0.057 \t Time elapsed: 4.077 hr\n",
      "Steps: 61158/156300 \t loss (ema): 0.051 \t Time elapsed: 4.083 hr\n",
      "Steps: 61258/156300 \t loss (ema): 0.054 \t Time elapsed: 4.090 hr\n",
      "Steps: 61358/156300 \t loss (ema): 0.049 \t Time elapsed: 4.097 hr\n",
      "Steps: 61458/156300 \t loss (ema): 0.055 \t Time elapsed: 4.103 hr\n",
      "Steps: 61558/156300 \t loss (ema): 0.057 \t Time elapsed: 4.110 hr\n",
      "Steps: 61658/156300 \t loss (ema): 0.050 \t Time elapsed: 4.117 hr\n",
      "Steps: 61758/156300 \t loss (ema): 0.043 \t Time elapsed: 4.123 hr\n",
      "Steps: 61858/156300 \t loss (ema): 0.055 \t Time elapsed: 4.130 hr\n",
      "Steps: 61958/156300 \t loss (ema): 0.050 \t Time elapsed: 4.137 hr\n",
      "Steps: 62058/156300 \t loss (ema): 0.052 \t Time elapsed: 4.144 hr\n",
      "Steps: 62158/156300 \t loss (ema): 0.056 \t Time elapsed: 4.150 hr\n",
      "Steps: 62258/156300 \t loss (ema): 0.056 \t Time elapsed: 4.157 hr\n",
      "Steps: 62358/156300 \t loss (ema): 0.062 \t Time elapsed: 4.164 hr\n",
      "Steps: 62458/156300 \t loss (ema): 0.059 \t Time elapsed: 4.170 hr\n",
      "Steps: 62521/156300 \t loss (ema): 0.053 \t Time elapsed: 4.175 hr\n",
      "Steps: 62621/156300 \t loss (ema): 0.047 \t Time elapsed: 4.181 hr\n",
      "Steps: 62721/156300 \t loss (ema): 0.054 \t Time elapsed: 4.188 hr\n",
      "Steps: 62821/156300 \t loss (ema): 0.051 \t Time elapsed: 4.195 hr\n",
      "Steps: 62921/156300 \t loss (ema): 0.053 \t Time elapsed: 4.201 hr\n",
      "Steps: 63021/156300 \t loss (ema): 0.061 \t Time elapsed: 4.208 hr\n",
      "Steps: 63121/156300 \t loss (ema): 0.057 \t Time elapsed: 4.215 hr\n",
      "Steps: 63221/156300 \t loss (ema): 0.047 \t Time elapsed: 4.221 hr\n",
      "Steps: 63321/156300 \t loss (ema): 0.049 \t Time elapsed: 4.228 hr\n",
      "Steps: 63421/156300 \t loss (ema): 0.057 \t Time elapsed: 4.235 hr\n",
      "Steps: 63521/156300 \t loss (ema): 0.054 \t Time elapsed: 4.241 hr\n",
      "Steps: 63621/156300 \t loss (ema): 0.060 \t Time elapsed: 4.248 hr\n",
      "Steps: 63721/156300 \t loss (ema): 0.063 \t Time elapsed: 4.255 hr\n",
      "Steps: 63821/156300 \t loss (ema): 0.052 \t Time elapsed: 4.261 hr\n",
      "Steps: 63921/156300 \t loss (ema): 0.051 \t Time elapsed: 4.268 hr\n",
      "Steps: 64021/156300 \t loss (ema): 0.048 \t Time elapsed: 4.275 hr\n",
      "Epoch 40 completed\n",
      "Steps: 64084/156300 \t loss (ema): 0.056 \t Time elapsed: 4.279 hr\n",
      "Steps: 64184/156300 \t loss (ema): 0.055 \t Time elapsed: 4.286 hr\n",
      "Steps: 64284/156300 \t loss (ema): 0.053 \t Time elapsed: 4.292 hr\n",
      "Steps: 64384/156300 \t loss (ema): 0.050 \t Time elapsed: 4.299 hr\n",
      "Steps: 64484/156300 \t loss (ema): 0.051 \t Time elapsed: 4.306 hr\n",
      "Steps: 64584/156300 \t loss (ema): 0.045 \t Time elapsed: 4.312 hr\n",
      "Steps: 64684/156300 \t loss (ema): 0.051 \t Time elapsed: 4.319 hr\n",
      "Steps: 64784/156300 \t loss (ema): 0.043 \t Time elapsed: 4.326 hr\n",
      "Steps: 64884/156300 \t loss (ema): 0.049 \t Time elapsed: 4.332 hr\n",
      "Steps: 64984/156300 \t loss (ema): 0.049 \t Time elapsed: 4.339 hr\n",
      "Steps: 65084/156300 \t loss (ema): 0.043 \t Time elapsed: 4.346 hr\n",
      "Steps: 65184/156300 \t loss (ema): 0.052 \t Time elapsed: 4.352 hr\n",
      "Steps: 65284/156300 \t loss (ema): 0.050 \t Time elapsed: 4.359 hr\n",
      "Steps: 65384/156300 \t loss (ema): 0.056 \t Time elapsed: 4.366 hr\n",
      "Steps: 65484/156300 \t loss (ema): 0.060 \t Time elapsed: 4.372 hr\n",
      "Steps: 65584/156300 \t loss (ema): 0.058 \t Time elapsed: 4.379 hr\n",
      "Steps: 65647/156300 \t loss (ema): 0.051 \t Time elapsed: 4.383 hr\n",
      "Steps: 65747/156300 \t loss (ema): 0.056 \t Time elapsed: 4.390 hr\n",
      "Steps: 65847/156300 \t loss (ema): 0.048 \t Time elapsed: 4.397 hr\n",
      "Steps: 65947/156300 \t loss (ema): 0.054 \t Time elapsed: 4.403 hr\n",
      "Steps: 66047/156300 \t loss (ema): 0.044 \t Time elapsed: 4.410 hr\n",
      "Steps: 66147/156300 \t loss (ema): 0.053 \t Time elapsed: 4.417 hr\n",
      "Steps: 66247/156300 \t loss (ema): 0.051 \t Time elapsed: 4.423 hr\n",
      "Steps: 66347/156300 \t loss (ema): 0.050 \t Time elapsed: 4.430 hr\n",
      "Steps: 66447/156300 \t loss (ema): 0.057 \t Time elapsed: 4.437 hr\n",
      "Steps: 66547/156300 \t loss (ema): 0.056 \t Time elapsed: 4.443 hr\n",
      "Steps: 66647/156300 \t loss (ema): 0.050 \t Time elapsed: 4.450 hr\n",
      "Steps: 66747/156300 \t loss (ema): 0.054 \t Time elapsed: 4.457 hr\n",
      "Steps: 66847/156300 \t loss (ema): 0.058 \t Time elapsed: 4.463 hr\n",
      "Steps: 66947/156300 \t loss (ema): 0.054 \t Time elapsed: 4.470 hr\n",
      "Steps: 67047/156300 \t loss (ema): 0.068 \t Time elapsed: 4.477 hr\n",
      "Steps: 67147/156300 \t loss (ema): 0.062 \t Time elapsed: 4.484 hr\n",
      "Steps: 67210/156300 \t loss (ema): 0.053 \t Time elapsed: 4.488 hr\n",
      "Steps: 67310/156300 \t loss (ema): 0.054 \t Time elapsed: 4.494 hr\n",
      "Steps: 67410/156300 \t loss (ema): 0.050 \t Time elapsed: 4.501 hr\n",
      "Steps: 67510/156300 \t loss (ema): 0.050 \t Time elapsed: 4.508 hr\n",
      "Steps: 67610/156300 \t loss (ema): 0.048 \t Time elapsed: 4.515 hr\n",
      "Steps: 67710/156300 \t loss (ema): 0.052 \t Time elapsed: 4.521 hr\n",
      "Steps: 67810/156300 \t loss (ema): 0.050 \t Time elapsed: 4.528 hr\n",
      "Steps: 67910/156300 \t loss (ema): 0.053 \t Time elapsed: 4.535 hr\n",
      "Steps: 68010/156300 \t loss (ema): 0.062 \t Time elapsed: 4.541 hr\n",
      "Steps: 68110/156300 \t loss (ema): 0.062 \t Time elapsed: 4.548 hr\n",
      "Steps: 68210/156300 \t loss (ema): 0.054 \t Time elapsed: 4.555 hr\n",
      "Steps: 68310/156300 \t loss (ema): 0.051 \t Time elapsed: 4.561 hr\n",
      "Steps: 68410/156300 \t loss (ema): 0.052 \t Time elapsed: 4.568 hr\n",
      "Steps: 68510/156300 \t loss (ema): 0.047 \t Time elapsed: 4.575 hr\n",
      "Steps: 68610/156300 \t loss (ema): 0.058 \t Time elapsed: 4.581 hr\n",
      "Steps: 68710/156300 \t loss (ema): 0.068 \t Time elapsed: 4.588 hr\n",
      "Steps: 68773/156300 \t loss (ema): 0.059 \t Time elapsed: 4.592 hr\n",
      "Steps: 68873/156300 \t loss (ema): 0.060 \t Time elapsed: 4.599 hr\n",
      "Steps: 68973/156300 \t loss (ema): 0.049 \t Time elapsed: 4.606 hr\n",
      "Steps: 69073/156300 \t loss (ema): 0.050 \t Time elapsed: 4.612 hr\n",
      "Steps: 69173/156300 \t loss (ema): 0.057 \t Time elapsed: 4.619 hr\n",
      "Steps: 69273/156300 \t loss (ema): 0.051 \t Time elapsed: 4.626 hr\n",
      "Steps: 69373/156300 \t loss (ema): 0.059 \t Time elapsed: 4.632 hr\n",
      "Steps: 69473/156300 \t loss (ema): 0.058 \t Time elapsed: 4.639 hr\n",
      "Steps: 69573/156300 \t loss (ema): 0.055 \t Time elapsed: 4.646 hr\n",
      "Steps: 69673/156300 \t loss (ema): 0.056 \t Time elapsed: 4.652 hr\n",
      "Steps: 69773/156300 \t loss (ema): 0.052 \t Time elapsed: 4.659 hr\n",
      "Steps: 69873/156300 \t loss (ema): 0.050 \t Time elapsed: 4.666 hr\n",
      "Steps: 69973/156300 \t loss (ema): 0.045 \t Time elapsed: 4.672 hr\n",
      "Steps: 70073/156300 \t loss (ema): 0.055 \t Time elapsed: 4.679 hr\n",
      "Steps: 70173/156300 \t loss (ema): 0.053 \t Time elapsed: 4.685 hr\n",
      "Steps: 70273/156300 \t loss (ema): 0.050 \t Time elapsed: 4.692 hr\n",
      "Steps: 70336/156300 \t loss (ema): 0.062 \t Time elapsed: 4.696 hr\n",
      "Steps: 70436/156300 \t loss (ema): 0.055 \t Time elapsed: 4.703 hr\n",
      "Steps: 70536/156300 \t loss (ema): 0.060 \t Time elapsed: 4.710 hr\n",
      "Steps: 70636/156300 \t loss (ema): 0.046 \t Time elapsed: 4.716 hr\n",
      "Steps: 70736/156300 \t loss (ema): 0.056 \t Time elapsed: 4.723 hr\n",
      "Steps: 70836/156300 \t loss (ema): 0.054 \t Time elapsed: 4.730 hr\n",
      "Steps: 70936/156300 \t loss (ema): 0.050 \t Time elapsed: 4.736 hr\n",
      "Steps: 71036/156300 \t loss (ema): 0.050 \t Time elapsed: 4.743 hr\n",
      "Steps: 71136/156300 \t loss (ema): 0.047 \t Time elapsed: 4.750 hr\n",
      "Steps: 71236/156300 \t loss (ema): 0.051 \t Time elapsed: 4.756 hr\n",
      "Steps: 71336/156300 \t loss (ema): 0.070 \t Time elapsed: 4.763 hr\n",
      "Steps: 71436/156300 \t loss (ema): 0.052 \t Time elapsed: 4.770 hr\n",
      "Steps: 71536/156300 \t loss (ema): 0.058 \t Time elapsed: 4.776 hr\n",
      "Steps: 71636/156300 \t loss (ema): 0.063 \t Time elapsed: 4.783 hr\n",
      "Steps: 71736/156300 \t loss (ema): 0.052 \t Time elapsed: 4.790 hr\n",
      "Steps: 71836/156300 \t loss (ema): 0.058 \t Time elapsed: 4.796 hr\n",
      "Steps: 71899/156300 \t loss (ema): 0.053 \t Time elapsed: 4.801 hr\n",
      "Steps: 71999/156300 \t loss (ema): 0.049 \t Time elapsed: 4.807 hr\n",
      "Steps: 72099/156300 \t loss (ema): 0.049 \t Time elapsed: 4.814 hr\n",
      "Steps: 72199/156300 \t loss (ema): 0.056 \t Time elapsed: 4.821 hr\n",
      "Steps: 72299/156300 \t loss (ema): 0.047 \t Time elapsed: 4.827 hr\n",
      "Steps: 72399/156300 \t loss (ema): 0.048 \t Time elapsed: 4.834 hr\n",
      "Steps: 72499/156300 \t loss (ema): 0.043 \t Time elapsed: 4.841 hr\n",
      "Steps: 72599/156300 \t loss (ema): 0.053 \t Time elapsed: 4.848 hr\n",
      "Steps: 72699/156300 \t loss (ema): 0.056 \t Time elapsed: 4.854 hr\n",
      "Steps: 72799/156300 \t loss (ema): 0.047 \t Time elapsed: 4.861 hr\n",
      "Steps: 72899/156300 \t loss (ema): 0.050 \t Time elapsed: 4.868 hr\n",
      "Steps: 72999/156300 \t loss (ema): 0.061 \t Time elapsed: 4.874 hr\n",
      "Steps: 73099/156300 \t loss (ema): 0.048 \t Time elapsed: 4.881 hr\n",
      "Steps: 73199/156300 \t loss (ema): 0.055 \t Time elapsed: 4.888 hr\n",
      "Steps: 73299/156300 \t loss (ema): 0.052 \t Time elapsed: 4.894 hr\n",
      "Steps: 73399/156300 \t loss (ema): 0.054 \t Time elapsed: 4.901 hr\n",
      "Steps: 73462/156300 \t loss (ema): 0.057 \t Time elapsed: 4.905 hr\n",
      "Steps: 73562/156300 \t loss (ema): 0.062 \t Time elapsed: 4.912 hr\n",
      "Steps: 73662/156300 \t loss (ema): 0.049 \t Time elapsed: 4.919 hr\n",
      "Steps: 73762/156300 \t loss (ema): 0.050 \t Time elapsed: 4.925 hr\n",
      "Steps: 73862/156300 \t loss (ema): 0.050 \t Time elapsed: 4.932 hr\n",
      "Steps: 73962/156300 \t loss (ema): 0.050 \t Time elapsed: 4.939 hr\n",
      "Steps: 74062/156300 \t loss (ema): 0.051 \t Time elapsed: 4.945 hr\n",
      "Steps: 74162/156300 \t loss (ema): 0.052 \t Time elapsed: 4.952 hr\n",
      "Steps: 74262/156300 \t loss (ema): 0.061 \t Time elapsed: 4.959 hr\n",
      "Steps: 74362/156300 \t loss (ema): 0.062 \t Time elapsed: 4.965 hr\n",
      "Steps: 74462/156300 \t loss (ema): 0.054 \t Time elapsed: 4.972 hr\n",
      "Steps: 74562/156300 \t loss (ema): 0.049 \t Time elapsed: 4.979 hr\n",
      "Steps: 74662/156300 \t loss (ema): 0.050 \t Time elapsed: 4.985 hr\n",
      "Steps: 74762/156300 \t loss (ema): 0.055 \t Time elapsed: 4.992 hr\n",
      "Steps: 74862/156300 \t loss (ema): 0.045 \t Time elapsed: 4.999 hr\n",
      "Steps: 74962/156300 \t loss (ema): 0.048 \t Time elapsed: 5.005 hr\n",
      "Steps: 75025/156300 \t loss (ema): 0.044 \t Time elapsed: 5.009 hr\n",
      "Steps: 75125/156300 \t loss (ema): 0.052 \t Time elapsed: 5.016 hr\n",
      "Steps: 75225/156300 \t loss (ema): 0.050 \t Time elapsed: 5.023 hr\n",
      "Steps: 75325/156300 \t loss (ema): 0.048 \t Time elapsed: 5.029 hr\n",
      "Steps: 75425/156300 \t loss (ema): 0.052 \t Time elapsed: 5.036 hr\n",
      "Steps: 75525/156300 \t loss (ema): 0.049 \t Time elapsed: 5.043 hr\n",
      "Steps: 75625/156300 \t loss (ema): 0.060 \t Time elapsed: 5.049 hr\n",
      "Steps: 75725/156300 \t loss (ema): 0.047 \t Time elapsed: 5.056 hr\n",
      "Steps: 75825/156300 \t loss (ema): 0.051 \t Time elapsed: 5.063 hr\n",
      "Steps: 75925/156300 \t loss (ema): 0.045 \t Time elapsed: 5.069 hr\n",
      "Steps: 76025/156300 \t loss (ema): 0.051 \t Time elapsed: 5.076 hr\n",
      "Steps: 76125/156300 \t loss (ema): 0.052 \t Time elapsed: 5.083 hr\n",
      "Steps: 76225/156300 \t loss (ema): 0.052 \t Time elapsed: 5.089 hr\n",
      "Steps: 76325/156300 \t loss (ema): 0.054 \t Time elapsed: 5.096 hr\n",
      "Steps: 76425/156300 \t loss (ema): 0.052 \t Time elapsed: 5.103 hr\n",
      "Steps: 76525/156300 \t loss (ema): 0.057 \t Time elapsed: 5.109 hr\n",
      "Steps: 76588/156300 \t loss (ema): 0.046 \t Time elapsed: 5.114 hr\n",
      "Steps: 76688/156300 \t loss (ema): 0.058 \t Time elapsed: 5.120 hr\n",
      "Steps: 76788/156300 \t loss (ema): 0.043 \t Time elapsed: 5.127 hr\n",
      "Steps: 76888/156300 \t loss (ema): 0.055 \t Time elapsed: 5.134 hr\n",
      "Steps: 76988/156300 \t loss (ema): 0.051 \t Time elapsed: 5.140 hr\n",
      "Steps: 77088/156300 \t loss (ema): 0.051 \t Time elapsed: 5.147 hr\n",
      "Steps: 77188/156300 \t loss (ema): 0.048 \t Time elapsed: 5.154 hr\n",
      "Steps: 77288/156300 \t loss (ema): 0.056 \t Time elapsed: 5.160 hr\n",
      "Steps: 77388/156300 \t loss (ema): 0.058 \t Time elapsed: 5.167 hr\n",
      "Steps: 77488/156300 \t loss (ema): 0.051 \t Time elapsed: 5.174 hr\n",
      "Steps: 77588/156300 \t loss (ema): 0.047 \t Time elapsed: 5.180 hr\n",
      "Steps: 77688/156300 \t loss (ema): 0.054 \t Time elapsed: 5.187 hr\n",
      "Steps: 77788/156300 \t loss (ema): 0.049 \t Time elapsed: 5.194 hr\n",
      "Steps: 77888/156300 \t loss (ema): 0.051 \t Time elapsed: 5.201 hr\n",
      "Steps: 77988/156300 \t loss (ema): 0.057 \t Time elapsed: 5.207 hr\n",
      "Steps: 78088/156300 \t loss (ema): 0.049 \t Time elapsed: 5.214 hr\n",
      "Steps: 78151/156300 \t loss (ema): 0.053 \t Time elapsed: 5.218 hr\n",
      "Steps: 78251/156300 \t loss (ema): 0.060 \t Time elapsed: 5.225 hr\n",
      "Steps: 78351/156300 \t loss (ema): 0.055 \t Time elapsed: 5.232 hr\n",
      "Steps: 78451/156300 \t loss (ema): 0.053 \t Time elapsed: 5.238 hr\n",
      "Steps: 78551/156300 \t loss (ema): 0.051 \t Time elapsed: 5.245 hr\n",
      "Steps: 78651/156300 \t loss (ema): 0.061 \t Time elapsed: 5.252 hr\n",
      "Steps: 78751/156300 \t loss (ema): 0.061 \t Time elapsed: 5.258 hr\n",
      "Steps: 78851/156300 \t loss (ema): 0.068 \t Time elapsed: 5.265 hr\n",
      "Steps: 78951/156300 \t loss (ema): 0.055 \t Time elapsed: 5.272 hr\n",
      "Steps: 79051/156300 \t loss (ema): 0.052 \t Time elapsed: 5.279 hr\n",
      "Steps: 79151/156300 \t loss (ema): 0.050 \t Time elapsed: 5.285 hr\n",
      "Steps: 79251/156300 \t loss (ema): 0.040 \t Time elapsed: 5.292 hr\n",
      "Steps: 79351/156300 \t loss (ema): 0.052 \t Time elapsed: 5.299 hr\n",
      "Steps: 79451/156300 \t loss (ema): 0.054 \t Time elapsed: 5.305 hr\n",
      "Steps: 79551/156300 \t loss (ema): 0.051 \t Time elapsed: 5.312 hr\n",
      "Steps: 79651/156300 \t loss (ema): 0.055 \t Time elapsed: 5.319 hr\n",
      "Epoch 50 completed\n",
      "Steps: 79714/156300 \t loss (ema): 0.053 \t Time elapsed: 5.323 hr\n",
      "Steps: 79814/156300 \t loss (ema): 0.050 \t Time elapsed: 5.330 hr\n",
      "Steps: 79914/156300 \t loss (ema): 0.054 \t Time elapsed: 5.336 hr\n",
      "Steps: 80014/156300 \t loss (ema): 0.065 \t Time elapsed: 5.343 hr\n",
      "Steps: 80114/156300 \t loss (ema): 0.058 \t Time elapsed: 5.350 hr\n",
      "Steps: 80214/156300 \t loss (ema): 0.053 \t Time elapsed: 5.356 hr\n",
      "Steps: 80314/156300 \t loss (ema): 0.053 \t Time elapsed: 5.363 hr\n",
      "Steps: 80414/156300 \t loss (ema): 0.051 \t Time elapsed: 5.370 hr\n",
      "Steps: 80514/156300 \t loss (ema): 0.053 \t Time elapsed: 5.376 hr\n",
      "Steps: 80614/156300 \t loss (ema): 0.046 \t Time elapsed: 5.383 hr\n",
      "Steps: 80714/156300 \t loss (ema): 0.057 \t Time elapsed: 5.390 hr\n",
      "Steps: 80814/156300 \t loss (ema): 0.057 \t Time elapsed: 5.396 hr\n",
      "Steps: 80914/156300 \t loss (ema): 0.060 \t Time elapsed: 5.403 hr\n",
      "Steps: 81014/156300 \t loss (ema): 0.051 \t Time elapsed: 5.410 hr\n",
      "Steps: 81114/156300 \t loss (ema): 0.049 \t Time elapsed: 5.416 hr\n",
      "Steps: 81214/156300 \t loss (ema): 0.054 \t Time elapsed: 5.423 hr\n",
      "Steps: 81277/156300 \t loss (ema): 0.050 \t Time elapsed: 5.427 hr\n",
      "Steps: 81377/156300 \t loss (ema): 0.050 \t Time elapsed: 5.434 hr\n",
      "Steps: 81477/156300 \t loss (ema): 0.056 \t Time elapsed: 5.440 hr\n",
      "Steps: 81577/156300 \t loss (ema): 0.048 \t Time elapsed: 5.447 hr\n",
      "Steps: 81677/156300 \t loss (ema): 0.054 \t Time elapsed: 5.454 hr\n",
      "Steps: 81777/156300 \t loss (ema): 0.054 \t Time elapsed: 5.461 hr\n",
      "Steps: 81877/156300 \t loss (ema): 0.058 \t Time elapsed: 5.467 hr\n",
      "Steps: 81977/156300 \t loss (ema): 0.047 \t Time elapsed: 5.474 hr\n",
      "Steps: 82077/156300 \t loss (ema): 0.049 \t Time elapsed: 5.481 hr\n",
      "Steps: 82177/156300 \t loss (ema): 0.055 \t Time elapsed: 5.487 hr\n",
      "Steps: 82277/156300 \t loss (ema): 0.053 \t Time elapsed: 5.494 hr\n",
      "Steps: 82377/156300 \t loss (ema): 0.043 \t Time elapsed: 5.501 hr\n",
      "Steps: 82477/156300 \t loss (ema): 0.052 \t Time elapsed: 5.507 hr\n",
      "Steps: 82577/156300 \t loss (ema): 0.048 \t Time elapsed: 5.514 hr\n",
      "Steps: 82677/156300 \t loss (ema): 0.049 \t Time elapsed: 5.521 hr\n",
      "Steps: 82777/156300 \t loss (ema): 0.052 \t Time elapsed: 5.527 hr\n",
      "Steps: 82840/156300 \t loss (ema): 0.047 \t Time elapsed: 5.532 hr\n",
      "Steps: 82940/156300 \t loss (ema): 0.058 \t Time elapsed: 5.538 hr\n",
      "Steps: 83040/156300 \t loss (ema): 0.043 \t Time elapsed: 5.545 hr\n",
      "Steps: 83140/156300 \t loss (ema): 0.063 \t Time elapsed: 5.552 hr\n",
      "Steps: 83240/156300 \t loss (ema): 0.058 \t Time elapsed: 5.558 hr\n",
      "Steps: 83340/156300 \t loss (ema): 0.055 \t Time elapsed: 5.565 hr\n",
      "Steps: 83440/156300 \t loss (ema): 0.058 \t Time elapsed: 5.572 hr\n",
      "Steps: 83540/156300 \t loss (ema): 0.044 \t Time elapsed: 5.578 hr\n",
      "Steps: 83640/156300 \t loss (ema): 0.054 \t Time elapsed: 5.585 hr\n",
      "Steps: 83740/156300 \t loss (ema): 0.050 \t Time elapsed: 5.592 hr\n",
      "Steps: 83840/156300 \t loss (ema): 0.057 \t Time elapsed: 5.599 hr\n",
      "Steps: 83940/156300 \t loss (ema): 0.056 \t Time elapsed: 5.605 hr\n",
      "Steps: 84040/156300 \t loss (ema): 0.054 \t Time elapsed: 5.612 hr\n",
      "Steps: 84140/156300 \t loss (ema): 0.053 \t Time elapsed: 5.619 hr\n",
      "Steps: 84240/156300 \t loss (ema): 0.055 \t Time elapsed: 5.625 hr\n",
      "Steps: 84340/156300 \t loss (ema): 0.048 \t Time elapsed: 5.632 hr\n",
      "Steps: 84403/156300 \t loss (ema): 0.049 \t Time elapsed: 5.636 hr\n",
      "Steps: 84503/156300 \t loss (ema): 0.048 \t Time elapsed: 5.643 hr\n",
      "Steps: 84603/156300 \t loss (ema): 0.054 \t Time elapsed: 5.650 hr\n",
      "Steps: 84703/156300 \t loss (ema): 0.053 \t Time elapsed: 5.656 hr\n",
      "Steps: 84803/156300 \t loss (ema): 0.052 \t Time elapsed: 5.663 hr\n",
      "Steps: 84903/156300 \t loss (ema): 0.060 \t Time elapsed: 5.670 hr\n",
      "Steps: 85003/156300 \t loss (ema): 0.059 \t Time elapsed: 5.676 hr\n",
      "Steps: 85103/156300 \t loss (ema): 0.049 \t Time elapsed: 5.683 hr\n",
      "Steps: 85203/156300 \t loss (ema): 0.051 \t Time elapsed: 5.689 hr\n",
      "Steps: 85303/156300 \t loss (ema): 0.049 \t Time elapsed: 5.696 hr\n",
      "Steps: 85403/156300 \t loss (ema): 0.049 \t Time elapsed: 5.703 hr\n",
      "Steps: 85503/156300 \t loss (ema): 0.051 \t Time elapsed: 5.709 hr\n",
      "Steps: 85603/156300 \t loss (ema): 0.056 \t Time elapsed: 5.716 hr\n",
      "Steps: 85703/156300 \t loss (ema): 0.050 \t Time elapsed: 5.723 hr\n",
      "Steps: 85803/156300 \t loss (ema): 0.049 \t Time elapsed: 5.729 hr\n",
      "Steps: 85903/156300 \t loss (ema): 0.055 \t Time elapsed: 5.736 hr\n",
      "Steps: 85966/156300 \t loss (ema): 0.056 \t Time elapsed: 5.740 hr\n",
      "Steps: 86066/156300 \t loss (ema): 0.054 \t Time elapsed: 5.747 hr\n",
      "Steps: 86166/156300 \t loss (ema): 0.049 \t Time elapsed: 5.754 hr\n",
      "Steps: 86266/156300 \t loss (ema): 0.057 \t Time elapsed: 5.760 hr\n",
      "Steps: 86366/156300 \t loss (ema): 0.054 \t Time elapsed: 5.767 hr\n",
      "Steps: 86466/156300 \t loss (ema): 0.054 \t Time elapsed: 5.774 hr\n",
      "Steps: 86566/156300 \t loss (ema): 0.053 \t Time elapsed: 5.780 hr\n",
      "Steps: 86666/156300 \t loss (ema): 0.054 \t Time elapsed: 5.787 hr\n",
      "Steps: 86766/156300 \t loss (ema): 0.050 \t Time elapsed: 5.794 hr\n",
      "Steps: 86866/156300 \t loss (ema): 0.057 \t Time elapsed: 5.800 hr\n",
      "Steps: 86966/156300 \t loss (ema): 0.047 \t Time elapsed: 5.807 hr\n",
      "Steps: 87066/156300 \t loss (ema): 0.061 \t Time elapsed: 5.814 hr\n",
      "Steps: 87166/156300 \t loss (ema): 0.051 \t Time elapsed: 5.820 hr\n",
      "Steps: 87266/156300 \t loss (ema): 0.053 \t Time elapsed: 5.827 hr\n",
      "Steps: 87366/156300 \t loss (ema): 0.052 \t Time elapsed: 5.834 hr\n",
      "Steps: 87466/156300 \t loss (ema): 0.045 \t Time elapsed: 5.840 hr\n",
      "Steps: 87529/156300 \t loss (ema): 0.056 \t Time elapsed: 5.845 hr\n",
      "Steps: 87629/156300 \t loss (ema): 0.056 \t Time elapsed: 5.851 hr\n",
      "Steps: 87729/156300 \t loss (ema): 0.066 \t Time elapsed: 5.858 hr\n",
      "Steps: 87829/156300 \t loss (ema): 0.048 \t Time elapsed: 5.865 hr\n",
      "Steps: 87929/156300 \t loss (ema): 0.058 \t Time elapsed: 5.871 hr\n",
      "Steps: 88029/156300 \t loss (ema): 0.055 \t Time elapsed: 5.878 hr\n",
      "Steps: 88129/156300 \t loss (ema): 0.054 \t Time elapsed: 5.885 hr\n",
      "Steps: 88229/156300 \t loss (ema): 0.057 \t Time elapsed: 5.891 hr\n",
      "Steps: 88329/156300 \t loss (ema): 0.048 \t Time elapsed: 5.898 hr\n",
      "Steps: 88429/156300 \t loss (ema): 0.050 \t Time elapsed: 5.905 hr\n",
      "Steps: 88529/156300 \t loss (ema): 0.051 \t Time elapsed: 5.912 hr\n",
      "Steps: 88629/156300 \t loss (ema): 0.048 \t Time elapsed: 5.918 hr\n",
      "Steps: 88729/156300 \t loss (ema): 0.046 \t Time elapsed: 5.925 hr\n",
      "Steps: 88829/156300 \t loss (ema): 0.052 \t Time elapsed: 5.932 hr\n",
      "Steps: 88929/156300 \t loss (ema): 0.050 \t Time elapsed: 5.938 hr\n",
      "Steps: 89029/156300 \t loss (ema): 0.052 \t Time elapsed: 5.945 hr\n",
      "Steps: 89092/156300 \t loss (ema): 0.055 \t Time elapsed: 5.949 hr\n",
      "Steps: 89192/156300 \t loss (ema): 0.051 \t Time elapsed: 5.956 hr\n",
      "Steps: 89292/156300 \t loss (ema): 0.053 \t Time elapsed: 5.963 hr\n",
      "Steps: 89392/156300 \t loss (ema): 0.051 \t Time elapsed: 5.969 hr\n",
      "Steps: 89492/156300 \t loss (ema): 0.049 \t Time elapsed: 5.976 hr\n",
      "Steps: 89592/156300 \t loss (ema): 0.051 \t Time elapsed: 5.983 hr\n",
      "Steps: 89692/156300 \t loss (ema): 0.053 \t Time elapsed: 5.989 hr\n",
      "Steps: 89792/156300 \t loss (ema): 0.061 \t Time elapsed: 5.996 hr\n",
      "Steps: 89892/156300 \t loss (ema): 0.044 \t Time elapsed: 6.003 hr\n",
      "Steps: 89992/156300 \t loss (ema): 0.051 \t Time elapsed: 6.009 hr\n",
      "Steps: 90092/156300 \t loss (ema): 0.066 \t Time elapsed: 6.016 hr\n",
      "Steps: 90192/156300 \t loss (ema): 0.060 \t Time elapsed: 6.023 hr\n",
      "Steps: 90292/156300 \t loss (ema): 0.051 \t Time elapsed: 6.029 hr\n",
      "Steps: 90392/156300 \t loss (ema): 0.054 \t Time elapsed: 6.036 hr\n",
      "Steps: 90492/156300 \t loss (ema): 0.061 \t Time elapsed: 6.043 hr\n",
      "Steps: 90592/156300 \t loss (ema): 0.045 \t Time elapsed: 6.049 hr\n",
      "Steps: 90655/156300 \t loss (ema): 0.056 \t Time elapsed: 6.054 hr\n",
      "Steps: 90755/156300 \t loss (ema): 0.050 \t Time elapsed: 6.060 hr\n",
      "Steps: 90855/156300 \t loss (ema): 0.049 \t Time elapsed: 6.067 hr\n",
      "Steps: 90955/156300 \t loss (ema): 0.058 \t Time elapsed: 6.074 hr\n",
      "Steps: 91055/156300 \t loss (ema): 0.048 \t Time elapsed: 6.080 hr\n",
      "Steps: 91155/156300 \t loss (ema): 0.049 \t Time elapsed: 6.087 hr\n",
      "Steps: 91255/156300 \t loss (ema): 0.066 \t Time elapsed: 6.093 hr\n",
      "Steps: 91355/156300 \t loss (ema): 0.051 \t Time elapsed: 6.100 hr\n",
      "Steps: 91455/156300 \t loss (ema): 0.055 \t Time elapsed: 6.107 hr\n",
      "Steps: 91555/156300 \t loss (ema): 0.056 \t Time elapsed: 6.113 hr\n",
      "Steps: 91655/156300 \t loss (ema): 0.064 \t Time elapsed: 6.120 hr\n",
      "Steps: 91755/156300 \t loss (ema): 0.054 \t Time elapsed: 6.127 hr\n",
      "Steps: 91855/156300 \t loss (ema): 0.052 \t Time elapsed: 6.133 hr\n",
      "Steps: 91955/156300 \t loss (ema): 0.045 \t Time elapsed: 6.140 hr\n",
      "Steps: 92055/156300 \t loss (ema): 0.061 \t Time elapsed: 6.147 hr\n",
      "Steps: 92155/156300 \t loss (ema): 0.057 \t Time elapsed: 6.153 hr\n",
      "Steps: 92218/156300 \t loss (ema): 0.049 \t Time elapsed: 6.158 hr\n",
      "Steps: 92318/156300 \t loss (ema): 0.054 \t Time elapsed: 6.164 hr\n",
      "Steps: 92418/156300 \t loss (ema): 0.044 \t Time elapsed: 6.171 hr\n",
      "Steps: 92518/156300 \t loss (ema): 0.049 \t Time elapsed: 6.178 hr\n",
      "Steps: 92618/156300 \t loss (ema): 0.053 \t Time elapsed: 6.184 hr\n",
      "Steps: 92718/156300 \t loss (ema): 0.053 \t Time elapsed: 6.191 hr\n",
      "Steps: 92818/156300 \t loss (ema): 0.055 \t Time elapsed: 6.198 hr\n",
      "Steps: 92918/156300 \t loss (ema): 0.057 \t Time elapsed: 6.204 hr\n",
      "Steps: 93018/156300 \t loss (ema): 0.054 \t Time elapsed: 6.211 hr\n",
      "Steps: 93118/156300 \t loss (ema): 0.052 \t Time elapsed: 6.218 hr\n",
      "Steps: 93218/156300 \t loss (ema): 0.051 \t Time elapsed: 6.224 hr\n",
      "Steps: 93318/156300 \t loss (ema): 0.054 \t Time elapsed: 6.231 hr\n",
      "Steps: 93418/156300 \t loss (ema): 0.049 \t Time elapsed: 6.238 hr\n",
      "Steps: 93518/156300 \t loss (ema): 0.042 \t Time elapsed: 6.245 hr\n",
      "Steps: 93618/156300 \t loss (ema): 0.059 \t Time elapsed: 6.251 hr\n",
      "Steps: 93718/156300 \t loss (ema): 0.049 \t Time elapsed: 6.258 hr\n",
      "Steps: 93781/156300 \t loss (ema): 0.063 \t Time elapsed: 6.262 hr\n",
      "Steps: 93881/156300 \t loss (ema): 0.046 \t Time elapsed: 6.269 hr\n",
      "Steps: 93981/156300 \t loss (ema): 0.045 \t Time elapsed: 6.276 hr\n",
      "Steps: 94081/156300 \t loss (ema): 0.042 \t Time elapsed: 6.282 hr\n",
      "Steps: 94181/156300 \t loss (ema): 0.059 \t Time elapsed: 6.289 hr\n",
      "Steps: 94281/156300 \t loss (ema): 0.056 \t Time elapsed: 6.296 hr\n",
      "Steps: 94381/156300 \t loss (ema): 0.054 \t Time elapsed: 6.302 hr\n",
      "Steps: 94481/156300 \t loss (ema): 0.052 \t Time elapsed: 6.309 hr\n",
      "Steps: 94581/156300 \t loss (ema): 0.047 \t Time elapsed: 6.316 hr\n",
      "Steps: 94681/156300 \t loss (ema): 0.054 \t Time elapsed: 6.322 hr\n",
      "Steps: 94781/156300 \t loss (ema): 0.050 \t Time elapsed: 6.329 hr\n",
      "Steps: 94881/156300 \t loss (ema): 0.055 \t Time elapsed: 6.336 hr\n",
      "Steps: 94981/156300 \t loss (ema): 0.054 \t Time elapsed: 6.343 hr\n",
      "Steps: 95081/156300 \t loss (ema): 0.051 \t Time elapsed: 6.349 hr\n",
      "Steps: 95181/156300 \t loss (ema): 0.049 \t Time elapsed: 6.356 hr\n",
      "Steps: 95281/156300 \t loss (ema): 0.055 \t Time elapsed: 6.363 hr\n",
      "Epoch 60 completed\n",
      "Steps: 95344/156300 \t loss (ema): 0.049 \t Time elapsed: 6.367 hr\n",
      "Steps: 95444/156300 \t loss (ema): 0.048 \t Time elapsed: 6.374 hr\n",
      "Steps: 95544/156300 \t loss (ema): 0.061 \t Time elapsed: 6.380 hr\n",
      "Steps: 95644/156300 \t loss (ema): 0.052 \t Time elapsed: 6.387 hr\n",
      "Steps: 95744/156300 \t loss (ema): 0.056 \t Time elapsed: 6.394 hr\n",
      "Steps: 95844/156300 \t loss (ema): 0.051 \t Time elapsed: 6.400 hr\n",
      "Steps: 95944/156300 \t loss (ema): 0.060 \t Time elapsed: 6.407 hr\n",
      "Steps: 96044/156300 \t loss (ema): 0.047 \t Time elapsed: 6.414 hr\n",
      "Steps: 96144/156300 \t loss (ema): 0.042 \t Time elapsed: 6.420 hr\n",
      "Steps: 96244/156300 \t loss (ema): 0.060 \t Time elapsed: 6.427 hr\n",
      "Steps: 96344/156300 \t loss (ema): 0.058 \t Time elapsed: 6.434 hr\n",
      "Steps: 96444/156300 \t loss (ema): 0.053 \t Time elapsed: 6.440 hr\n",
      "Steps: 96544/156300 \t loss (ema): 0.049 \t Time elapsed: 6.447 hr\n",
      "Steps: 96644/156300 \t loss (ema): 0.053 \t Time elapsed: 6.454 hr\n",
      "Steps: 96744/156300 \t loss (ema): 0.047 \t Time elapsed: 6.460 hr\n",
      "Steps: 96844/156300 \t loss (ema): 0.054 \t Time elapsed: 6.467 hr\n",
      "Steps: 96907/156300 \t loss (ema): 0.048 \t Time elapsed: 6.471 hr\n",
      "Steps: 97007/156300 \t loss (ema): 0.046 \t Time elapsed: 6.478 hr\n",
      "Steps: 97107/156300 \t loss (ema): 0.048 \t Time elapsed: 6.484 hr\n",
      "Steps: 97207/156300 \t loss (ema): 0.052 \t Time elapsed: 6.491 hr\n",
      "Steps: 97307/156300 \t loss (ema): 0.047 \t Time elapsed: 6.498 hr\n",
      "Steps: 97407/156300 \t loss (ema): 0.052 \t Time elapsed: 6.504 hr\n",
      "Steps: 97507/156300 \t loss (ema): 0.059 \t Time elapsed: 6.511 hr\n",
      "Steps: 97607/156300 \t loss (ema): 0.043 \t Time elapsed: 6.518 hr\n",
      "Steps: 97707/156300 \t loss (ema): 0.049 \t Time elapsed: 6.524 hr\n",
      "Steps: 97807/156300 \t loss (ema): 0.054 \t Time elapsed: 6.531 hr\n",
      "Steps: 97907/156300 \t loss (ema): 0.054 \t Time elapsed: 6.538 hr\n",
      "Steps: 98007/156300 \t loss (ema): 0.052 \t Time elapsed: 6.545 hr\n",
      "Steps: 98107/156300 \t loss (ema): 0.054 \t Time elapsed: 6.551 hr\n",
      "Steps: 98207/156300 \t loss (ema): 0.052 \t Time elapsed: 6.558 hr\n",
      "Steps: 98307/156300 \t loss (ema): 0.048 \t Time elapsed: 6.565 hr\n",
      "Steps: 98407/156300 \t loss (ema): 0.052 \t Time elapsed: 6.571 hr\n",
      "Steps: 98470/156300 \t loss (ema): 0.054 \t Time elapsed: 6.576 hr\n",
      "Steps: 98570/156300 \t loss (ema): 0.062 \t Time elapsed: 6.582 hr\n",
      "Steps: 98670/156300 \t loss (ema): 0.045 \t Time elapsed: 6.589 hr\n",
      "Steps: 98770/156300 \t loss (ema): 0.056 \t Time elapsed: 6.596 hr\n",
      "Steps: 98870/156300 \t loss (ema): 0.053 \t Time elapsed: 6.602 hr\n",
      "Steps: 98970/156300 \t loss (ema): 0.048 \t Time elapsed: 6.609 hr\n",
      "Steps: 99070/156300 \t loss (ema): 0.042 \t Time elapsed: 6.616 hr\n",
      "Steps: 99170/156300 \t loss (ema): 0.053 \t Time elapsed: 6.622 hr\n",
      "Steps: 99270/156300 \t loss (ema): 0.058 \t Time elapsed: 6.629 hr\n",
      "Steps: 99370/156300 \t loss (ema): 0.046 \t Time elapsed: 6.636 hr\n",
      "Steps: 99470/156300 \t loss (ema): 0.055 \t Time elapsed: 6.642 hr\n",
      "Steps: 99570/156300 \t loss (ema): 0.057 \t Time elapsed: 6.649 hr\n",
      "Steps: 99670/156300 \t loss (ema): 0.046 \t Time elapsed: 6.656 hr\n",
      "Steps: 99770/156300 \t loss (ema): 0.057 \t Time elapsed: 6.663 hr\n",
      "Steps: 99870/156300 \t loss (ema): 0.056 \t Time elapsed: 6.669 hr\n",
      "Steps: 99970/156300 \t loss (ema): 0.049 \t Time elapsed: 6.676 hr\n",
      "Steps: 100033/156300 \t loss (ema): 0.053 \t Time elapsed: 6.680 hr\n",
      "Steps: 100133/156300 \t loss (ema): 0.049 \t Time elapsed: 6.687 hr\n",
      "Steps: 100233/156300 \t loss (ema): 0.056 \t Time elapsed: 6.694 hr\n",
      "Steps: 100333/156300 \t loss (ema): 0.051 \t Time elapsed: 6.700 hr\n",
      "Steps: 100433/156300 \t loss (ema): 0.055 \t Time elapsed: 6.707 hr\n",
      "Steps: 100533/156300 \t loss (ema): 0.056 \t Time elapsed: 6.714 hr\n",
      "Steps: 100633/156300 \t loss (ema): 0.053 \t Time elapsed: 6.720 hr\n",
      "Steps: 100733/156300 \t loss (ema): 0.067 \t Time elapsed: 6.727 hr\n",
      "Steps: 100833/156300 \t loss (ema): 0.046 \t Time elapsed: 6.734 hr\n",
      "Steps: 100933/156300 \t loss (ema): 0.049 \t Time elapsed: 6.740 hr\n",
      "Steps: 101033/156300 \t loss (ema): 0.058 \t Time elapsed: 6.747 hr\n",
      "Steps: 101133/156300 \t loss (ema): 0.048 \t Time elapsed: 6.754 hr\n",
      "Steps: 101233/156300 \t loss (ema): 0.051 \t Time elapsed: 6.760 hr\n",
      "Steps: 101333/156300 \t loss (ema): 0.053 \t Time elapsed: 6.767 hr\n",
      "Steps: 101433/156300 \t loss (ema): 0.051 \t Time elapsed: 6.773 hr\n",
      "Steps: 101533/156300 \t loss (ema): 0.051 \t Time elapsed: 6.780 hr\n",
      "Steps: 101596/156300 \t loss (ema): 0.055 \t Time elapsed: 6.784 hr\n",
      "Steps: 101696/156300 \t loss (ema): 0.045 \t Time elapsed: 6.790 hr\n",
      "Steps: 101796/156300 \t loss (ema): 0.058 \t Time elapsed: 6.797 hr\n",
      "Steps: 101896/156300 \t loss (ema): 0.049 \t Time elapsed: 6.803 hr\n",
      "Steps: 101996/156300 \t loss (ema): 0.052 \t Time elapsed: 6.810 hr\n",
      "Steps: 102096/156300 \t loss (ema): 0.059 \t Time elapsed: 6.816 hr\n",
      "Steps: 102196/156300 \t loss (ema): 0.051 \t Time elapsed: 6.822 hr\n",
      "Steps: 102296/156300 \t loss (ema): 0.050 \t Time elapsed: 6.829 hr\n",
      "Steps: 102396/156300 \t loss (ema): 0.058 \t Time elapsed: 6.835 hr\n",
      "Steps: 102496/156300 \t loss (ema): 0.049 \t Time elapsed: 6.842 hr\n",
      "Steps: 102596/156300 \t loss (ema): 0.045 \t Time elapsed: 6.848 hr\n",
      "Steps: 102696/156300 \t loss (ema): 0.046 \t Time elapsed: 6.855 hr\n",
      "Steps: 102796/156300 \t loss (ema): 0.055 \t Time elapsed: 6.861 hr\n",
      "Steps: 102896/156300 \t loss (ema): 0.057 \t Time elapsed: 6.868 hr\n",
      "Steps: 102996/156300 \t loss (ema): 0.052 \t Time elapsed: 6.874 hr\n",
      "Steps: 103096/156300 \t loss (ema): 0.057 \t Time elapsed: 6.881 hr\n",
      "Steps: 103159/156300 \t loss (ema): 0.054 \t Time elapsed: 6.885 hr\n",
      "Steps: 103259/156300 \t loss (ema): 0.058 \t Time elapsed: 6.891 hr\n",
      "Steps: 103359/156300 \t loss (ema): 0.054 \t Time elapsed: 6.898 hr\n",
      "Steps: 103459/156300 \t loss (ema): 0.053 \t Time elapsed: 6.904 hr\n",
      "Steps: 103559/156300 \t loss (ema): 0.037 \t Time elapsed: 6.911 hr\n",
      "Steps: 103659/156300 \t loss (ema): 0.049 \t Time elapsed: 6.917 hr\n",
      "Steps: 103759/156300 \t loss (ema): 0.052 \t Time elapsed: 6.924 hr\n",
      "Steps: 103859/156300 \t loss (ema): 0.047 \t Time elapsed: 6.930 hr\n",
      "Steps: 103959/156300 \t loss (ema): 0.044 \t Time elapsed: 6.937 hr\n",
      "Steps: 104059/156300 \t loss (ema): 0.047 \t Time elapsed: 6.943 hr\n",
      "Steps: 104159/156300 \t loss (ema): 0.057 \t Time elapsed: 6.949 hr\n",
      "Steps: 104259/156300 \t loss (ema): 0.051 \t Time elapsed: 6.956 hr\n",
      "Steps: 104359/156300 \t loss (ema): 0.063 \t Time elapsed: 6.963 hr\n",
      "Steps: 104459/156300 \t loss (ema): 0.054 \t Time elapsed: 6.970 hr\n",
      "Steps: 104559/156300 \t loss (ema): 0.052 \t Time elapsed: 6.976 hr\n",
      "Steps: 104659/156300 \t loss (ema): 0.054 \t Time elapsed: 6.983 hr\n",
      "Steps: 104722/156300 \t loss (ema): 0.051 \t Time elapsed: 6.988 hr\n",
      "Steps: 104822/156300 \t loss (ema): 0.054 \t Time elapsed: 6.994 hr\n",
      "Steps: 104922/156300 \t loss (ema): 0.046 \t Time elapsed: 7.001 hr\n",
      "Steps: 105022/156300 \t loss (ema): 0.057 \t Time elapsed: 7.008 hr\n",
      "Steps: 105122/156300 \t loss (ema): 0.052 \t Time elapsed: 7.015 hr\n",
      "Steps: 105222/156300 \t loss (ema): 0.042 \t Time elapsed: 7.022 hr\n",
      "Steps: 105322/156300 \t loss (ema): 0.048 \t Time elapsed: 7.029 hr\n",
      "Steps: 105422/156300 \t loss (ema): 0.053 \t Time elapsed: 7.035 hr\n",
      "Steps: 105522/156300 \t loss (ema): 0.063 \t Time elapsed: 7.042 hr\n",
      "Steps: 105622/156300 \t loss (ema): 0.053 \t Time elapsed: 7.049 hr\n",
      "Steps: 105722/156300 \t loss (ema): 0.046 \t Time elapsed: 7.056 hr\n",
      "Steps: 105822/156300 \t loss (ema): 0.063 \t Time elapsed: 7.063 hr\n",
      "Steps: 105922/156300 \t loss (ema): 0.053 \t Time elapsed: 7.069 hr\n",
      "Steps: 106022/156300 \t loss (ema): 0.052 \t Time elapsed: 7.076 hr\n",
      "Steps: 106122/156300 \t loss (ema): 0.047 \t Time elapsed: 7.083 hr\n",
      "Steps: 106222/156300 \t loss (ema): 0.053 \t Time elapsed: 7.090 hr\n",
      "Steps: 106285/156300 \t loss (ema): 0.051 \t Time elapsed: 7.094 hr\n",
      "Steps: 106385/156300 \t loss (ema): 0.047 \t Time elapsed: 7.101 hr\n",
      "Steps: 106485/156300 \t loss (ema): 0.057 \t Time elapsed: 7.107 hr\n",
      "Steps: 106585/156300 \t loss (ema): 0.060 \t Time elapsed: 7.114 hr\n",
      "Steps: 106685/156300 \t loss (ema): 0.049 \t Time elapsed: 7.121 hr\n",
      "Steps: 106785/156300 \t loss (ema): 0.055 \t Time elapsed: 7.127 hr\n",
      "Steps: 106885/156300 \t loss (ema): 0.050 \t Time elapsed: 7.134 hr\n",
      "Steps: 106985/156300 \t loss (ema): 0.048 \t Time elapsed: 7.141 hr\n",
      "Steps: 107085/156300 \t loss (ema): 0.059 \t Time elapsed: 7.148 hr\n",
      "Steps: 107185/156300 \t loss (ema): 0.054 \t Time elapsed: 7.155 hr\n",
      "Steps: 107285/156300 \t loss (ema): 0.055 \t Time elapsed: 7.162 hr\n",
      "Steps: 107385/156300 \t loss (ema): 0.051 \t Time elapsed: 7.168 hr\n",
      "Steps: 107485/156300 \t loss (ema): 0.059 \t Time elapsed: 7.175 hr\n",
      "Steps: 107585/156300 \t loss (ema): 0.061 \t Time elapsed: 7.182 hr\n",
      "Steps: 107685/156300 \t loss (ema): 0.056 \t Time elapsed: 7.189 hr\n",
      "Steps: 107785/156300 \t loss (ema): 0.053 \t Time elapsed: 7.195 hr\n",
      "Steps: 107848/156300 \t loss (ema): 0.049 \t Time elapsed: 7.200 hr\n",
      "Steps: 107948/156300 \t loss (ema): 0.053 \t Time elapsed: 7.207 hr\n",
      "Steps: 108048/156300 \t loss (ema): 0.063 \t Time elapsed: 7.213 hr\n",
      "Steps: 108148/156300 \t loss (ema): 0.063 \t Time elapsed: 7.220 hr\n",
      "Steps: 108248/156300 \t loss (ema): 0.056 \t Time elapsed: 7.227 hr\n",
      "Steps: 108348/156300 \t loss (ema): 0.047 \t Time elapsed: 7.234 hr\n",
      "Steps: 108448/156300 \t loss (ema): 0.048 \t Time elapsed: 7.240 hr\n",
      "Steps: 108548/156300 \t loss (ema): 0.053 \t Time elapsed: 7.247 hr\n",
      "Steps: 108648/156300 \t loss (ema): 0.044 \t Time elapsed: 7.254 hr\n",
      "Steps: 108748/156300 \t loss (ema): 0.062 \t Time elapsed: 7.261 hr\n",
      "Steps: 108848/156300 \t loss (ema): 0.050 \t Time elapsed: 7.267 hr\n",
      "Steps: 108948/156300 \t loss (ema): 0.058 \t Time elapsed: 7.274 hr\n",
      "Steps: 109048/156300 \t loss (ema): 0.051 \t Time elapsed: 7.281 hr\n",
      "Steps: 109148/156300 \t loss (ema): 0.051 \t Time elapsed: 7.288 hr\n",
      "Steps: 109248/156300 \t loss (ema): 0.053 \t Time elapsed: 7.294 hr\n",
      "Steps: 109348/156300 \t loss (ema): 0.061 \t Time elapsed: 7.301 hr\n",
      "Steps: 109411/156300 \t loss (ema): 0.053 \t Time elapsed: 7.305 hr\n",
      "Steps: 109511/156300 \t loss (ema): 0.057 \t Time elapsed: 7.312 hr\n",
      "Steps: 109611/156300 \t loss (ema): 0.059 \t Time elapsed: 7.319 hr\n",
      "Steps: 109711/156300 \t loss (ema): 0.042 \t Time elapsed: 7.326 hr\n",
      "Steps: 109811/156300 \t loss (ema): 0.055 \t Time elapsed: 7.333 hr\n",
      "Steps: 109911/156300 \t loss (ema): 0.050 \t Time elapsed: 7.339 hr\n",
      "Steps: 110011/156300 \t loss (ema): 0.049 \t Time elapsed: 7.346 hr\n",
      "Steps: 110111/156300 \t loss (ema): 0.057 \t Time elapsed: 7.353 hr\n",
      "Steps: 110211/156300 \t loss (ema): 0.052 \t Time elapsed: 7.360 hr\n",
      "Steps: 110311/156300 \t loss (ema): 0.054 \t Time elapsed: 7.367 hr\n",
      "Steps: 110411/156300 \t loss (ema): 0.054 \t Time elapsed: 7.373 hr\n",
      "Steps: 110511/156300 \t loss (ema): 0.041 \t Time elapsed: 7.380 hr\n",
      "Steps: 110611/156300 \t loss (ema): 0.060 \t Time elapsed: 7.387 hr\n",
      "Steps: 110711/156300 \t loss (ema): 0.052 \t Time elapsed: 7.394 hr\n",
      "Steps: 110811/156300 \t loss (ema): 0.057 \t Time elapsed: 7.400 hr\n",
      "Steps: 110911/156300 \t loss (ema): 0.052 \t Time elapsed: 7.407 hr\n",
      "Epoch 70 completed\n",
      "Steps: 110974/156300 \t loss (ema): 0.058 \t Time elapsed: 7.412 hr\n",
      "Steps: 111074/156300 \t loss (ema): 0.051 \t Time elapsed: 7.419 hr\n",
      "Steps: 111174/156300 \t loss (ema): 0.051 \t Time elapsed: 7.425 hr\n",
      "Steps: 111274/156300 \t loss (ema): 0.050 \t Time elapsed: 7.432 hr\n",
      "Steps: 111374/156300 \t loss (ema): 0.056 \t Time elapsed: 7.439 hr\n",
      "Steps: 111474/156300 \t loss (ema): 0.060 \t Time elapsed: 7.445 hr\n",
      "Steps: 111574/156300 \t loss (ema): 0.064 \t Time elapsed: 7.452 hr\n",
      "Steps: 111674/156300 \t loss (ema): 0.052 \t Time elapsed: 7.459 hr\n",
      "Steps: 111774/156300 \t loss (ema): 0.047 \t Time elapsed: 7.466 hr\n",
      "Steps: 111874/156300 \t loss (ema): 0.054 \t Time elapsed: 7.473 hr\n",
      "Steps: 111974/156300 \t loss (ema): 0.058 \t Time elapsed: 7.480 hr\n",
      "Steps: 112074/156300 \t loss (ema): 0.058 \t Time elapsed: 7.486 hr\n",
      "Steps: 112174/156300 \t loss (ema): 0.042 \t Time elapsed: 7.493 hr\n",
      "Steps: 112274/156300 \t loss (ema): 0.046 \t Time elapsed: 7.500 hr\n",
      "Steps: 112374/156300 \t loss (ema): 0.060 \t Time elapsed: 7.507 hr\n",
      "Steps: 112474/156300 \t loss (ema): 0.052 \t Time elapsed: 7.514 hr\n",
      "Steps: 112537/156300 \t loss (ema): 0.058 \t Time elapsed: 7.518 hr\n",
      "Steps: 112637/156300 \t loss (ema): 0.050 \t Time elapsed: 7.525 hr\n",
      "Steps: 112737/156300 \t loss (ema): 0.057 \t Time elapsed: 7.532 hr\n",
      "Steps: 112837/156300 \t loss (ema): 0.048 \t Time elapsed: 7.538 hr\n",
      "Steps: 112937/156300 \t loss (ema): 0.049 \t Time elapsed: 7.545 hr\n",
      "Steps: 113037/156300 \t loss (ema): 0.056 \t Time elapsed: 7.552 hr\n",
      "Steps: 113137/156300 \t loss (ema): 0.051 \t Time elapsed: 7.559 hr\n",
      "Steps: 113237/156300 \t loss (ema): 0.048 \t Time elapsed: 7.566 hr\n",
      "Steps: 113337/156300 \t loss (ema): 0.059 \t Time elapsed: 7.573 hr\n",
      "Steps: 113437/156300 \t loss (ema): 0.056 \t Time elapsed: 7.579 hr\n",
      "Steps: 113537/156300 \t loss (ema): 0.052 \t Time elapsed: 7.586 hr\n",
      "Steps: 113637/156300 \t loss (ema): 0.048 \t Time elapsed: 7.593 hr\n",
      "Steps: 113737/156300 \t loss (ema): 0.052 \t Time elapsed: 7.600 hr\n",
      "Steps: 113837/156300 \t loss (ema): 0.057 \t Time elapsed: 7.607 hr\n",
      "Steps: 113937/156300 \t loss (ema): 0.050 \t Time elapsed: 7.614 hr\n",
      "Steps: 114037/156300 \t loss (ema): 0.046 \t Time elapsed: 7.620 hr\n",
      "Steps: 114100/156300 \t loss (ema): 0.050 \t Time elapsed: 7.625 hr\n",
      "Steps: 114200/156300 \t loss (ema): 0.049 \t Time elapsed: 7.631 hr\n",
      "Steps: 114300/156300 \t loss (ema): 0.056 \t Time elapsed: 7.638 hr\n",
      "Steps: 114400/156300 \t loss (ema): 0.057 \t Time elapsed: 7.645 hr\n",
      "Steps: 114500/156300 \t loss (ema): 0.054 \t Time elapsed: 7.652 hr\n",
      "Steps: 114600/156300 \t loss (ema): 0.057 \t Time elapsed: 7.658 hr\n",
      "Steps: 114700/156300 \t loss (ema): 0.059 \t Time elapsed: 7.665 hr\n",
      "Steps: 114800/156300 \t loss (ema): 0.051 \t Time elapsed: 7.672 hr\n",
      "Steps: 114900/156300 \t loss (ema): 0.054 \t Time elapsed: 7.679 hr\n",
      "Steps: 115000/156300 \t loss (ema): 0.053 \t Time elapsed: 7.686 hr\n",
      "Steps: 115100/156300 \t loss (ema): 0.055 \t Time elapsed: 7.692 hr\n",
      "Steps: 115200/156300 \t loss (ema): 0.053 \t Time elapsed: 7.699 hr\n",
      "Steps: 115300/156300 \t loss (ema): 0.047 \t Time elapsed: 7.706 hr\n",
      "Steps: 115400/156300 \t loss (ema): 0.051 \t Time elapsed: 7.713 hr\n",
      "Steps: 115500/156300 \t loss (ema): 0.053 \t Time elapsed: 7.720 hr\n",
      "Steps: 115600/156300 \t loss (ema): 0.049 \t Time elapsed: 7.726 hr\n",
      "Steps: 115663/156300 \t loss (ema): 0.055 \t Time elapsed: 7.731 hr\n",
      "Steps: 115763/156300 \t loss (ema): 0.063 \t Time elapsed: 7.737 hr\n",
      "Steps: 115863/156300 \t loss (ema): 0.051 \t Time elapsed: 7.744 hr\n",
      "Steps: 115963/156300 \t loss (ema): 0.053 \t Time elapsed: 7.751 hr\n",
      "Steps: 116063/156300 \t loss (ema): 0.051 \t Time elapsed: 7.758 hr\n",
      "Steps: 116163/156300 \t loss (ema): 0.049 \t Time elapsed: 7.765 hr\n",
      "Steps: 116263/156300 \t loss (ema): 0.055 \t Time elapsed: 7.771 hr\n",
      "Steps: 116363/156300 \t loss (ema): 0.044 \t Time elapsed: 7.778 hr\n",
      "Steps: 116463/156300 \t loss (ema): 0.046 \t Time elapsed: 7.785 hr\n",
      "Steps: 116563/156300 \t loss (ema): 0.061 \t Time elapsed: 7.792 hr\n",
      "Steps: 116663/156300 \t loss (ema): 0.061 \t Time elapsed: 7.799 hr\n",
      "Steps: 116763/156300 \t loss (ema): 0.050 \t Time elapsed: 7.805 hr\n",
      "Steps: 116863/156300 \t loss (ema): 0.046 \t Time elapsed: 7.812 hr\n",
      "Steps: 116963/156300 \t loss (ema): 0.050 \t Time elapsed: 7.819 hr\n",
      "Steps: 117063/156300 \t loss (ema): 0.055 \t Time elapsed: 7.826 hr\n",
      "Steps: 117163/156300 \t loss (ema): 0.052 \t Time elapsed: 7.833 hr\n",
      "Steps: 117226/156300 \t loss (ema): 0.052 \t Time elapsed: 7.837 hr\n",
      "Steps: 117326/156300 \t loss (ema): 0.041 \t Time elapsed: 7.844 hr\n",
      "Steps: 117426/156300 \t loss (ema): 0.057 \t Time elapsed: 7.850 hr\n",
      "Steps: 117526/156300 \t loss (ema): 0.052 \t Time elapsed: 7.857 hr\n",
      "Steps: 117626/156300 \t loss (ema): 0.045 \t Time elapsed: 7.864 hr\n",
      "Steps: 117726/156300 \t loss (ema): 0.042 \t Time elapsed: 7.871 hr\n",
      "Steps: 117826/156300 \t loss (ema): 0.053 \t Time elapsed: 7.878 hr\n",
      "Steps: 117926/156300 \t loss (ema): 0.053 \t Time elapsed: 7.884 hr\n",
      "Steps: 118026/156300 \t loss (ema): 0.054 \t Time elapsed: 7.891 hr\n",
      "Steps: 118126/156300 \t loss (ema): 0.062 \t Time elapsed: 7.898 hr\n",
      "Steps: 118226/156300 \t loss (ema): 0.054 \t Time elapsed: 7.905 hr\n",
      "Steps: 118326/156300 \t loss (ema): 0.050 \t Time elapsed: 7.911 hr\n",
      "Steps: 118426/156300 \t loss (ema): 0.055 \t Time elapsed: 7.918 hr\n",
      "Steps: 118526/156300 \t loss (ema): 0.051 \t Time elapsed: 7.925 hr\n",
      "Steps: 118626/156300 \t loss (ema): 0.054 \t Time elapsed: 7.932 hr\n",
      "Steps: 118726/156300 \t loss (ema): 0.048 \t Time elapsed: 7.939 hr\n",
      "Steps: 118789/156300 \t loss (ema): 0.055 \t Time elapsed: 7.943 hr\n",
      "Steps: 118889/156300 \t loss (ema): 0.057 \t Time elapsed: 7.950 hr\n",
      "Steps: 118989/156300 \t loss (ema): 0.054 \t Time elapsed: 7.957 hr\n",
      "Steps: 119089/156300 \t loss (ema): 0.048 \t Time elapsed: 7.963 hr\n",
      "Steps: 119189/156300 \t loss (ema): 0.053 \t Time elapsed: 7.970 hr\n",
      "Steps: 119289/156300 \t loss (ema): 0.055 \t Time elapsed: 7.977 hr\n",
      "Steps: 119389/156300 \t loss (ema): 0.065 \t Time elapsed: 7.984 hr\n",
      "Steps: 119489/156300 \t loss (ema): 0.051 \t Time elapsed: 7.990 hr\n",
      "Steps: 119589/156300 \t loss (ema): 0.044 \t Time elapsed: 7.997 hr\n",
      "Steps: 119689/156300 \t loss (ema): 0.054 \t Time elapsed: 8.004 hr\n",
      "Steps: 119789/156300 \t loss (ema): 0.055 \t Time elapsed: 8.010 hr\n",
      "Steps: 119889/156300 \t loss (ema): 0.053 \t Time elapsed: 8.017 hr\n",
      "Steps: 119989/156300 \t loss (ema): 0.047 \t Time elapsed: 8.024 hr\n",
      "Steps: 120089/156300 \t loss (ema): 0.061 \t Time elapsed: 8.031 hr\n",
      "Steps: 120189/156300 \t loss (ema): 0.054 \t Time elapsed: 8.038 hr\n",
      "Steps: 120289/156300 \t loss (ema): 0.053 \t Time elapsed: 8.044 hr\n",
      "Steps: 120352/156300 \t loss (ema): 0.058 \t Time elapsed: 8.049 hr\n",
      "Steps: 120452/156300 \t loss (ema): 0.054 \t Time elapsed: 8.055 hr\n",
      "Steps: 120552/156300 \t loss (ema): 0.065 \t Time elapsed: 8.062 hr\n",
      "Steps: 120652/156300 \t loss (ema): 0.060 \t Time elapsed: 8.069 hr\n",
      "Steps: 120752/156300 \t loss (ema): 0.052 \t Time elapsed: 8.076 hr\n",
      "Steps: 120852/156300 \t loss (ema): 0.057 \t Time elapsed: 8.083 hr\n",
      "Steps: 120952/156300 \t loss (ema): 0.051 \t Time elapsed: 8.089 hr\n",
      "Steps: 121052/156300 \t loss (ema): 0.050 \t Time elapsed: 8.096 hr\n",
      "Steps: 121152/156300 \t loss (ema): 0.057 \t Time elapsed: 8.103 hr\n",
      "Steps: 121252/156300 \t loss (ema): 0.054 \t Time elapsed: 8.109 hr\n",
      "Steps: 121352/156300 \t loss (ema): 0.045 \t Time elapsed: 8.116 hr\n",
      "Steps: 121452/156300 \t loss (ema): 0.047 \t Time elapsed: 8.123 hr\n",
      "Steps: 121552/156300 \t loss (ema): 0.051 \t Time elapsed: 8.129 hr\n",
      "Steps: 121652/156300 \t loss (ema): 0.051 \t Time elapsed: 8.136 hr\n",
      "Steps: 121752/156300 \t loss (ema): 0.048 \t Time elapsed: 8.143 hr\n",
      "Steps: 121852/156300 \t loss (ema): 0.065 \t Time elapsed: 8.149 hr\n",
      "Steps: 121915/156300 \t loss (ema): 0.059 \t Time elapsed: 8.154 hr\n",
      "Steps: 122015/156300 \t loss (ema): 0.056 \t Time elapsed: 8.161 hr\n",
      "Steps: 122115/156300 \t loss (ema): 0.052 \t Time elapsed: 8.168 hr\n",
      "Steps: 122215/156300 \t loss (ema): 0.053 \t Time elapsed: 8.174 hr\n",
      "Steps: 122315/156300 \t loss (ema): 0.048 \t Time elapsed: 8.181 hr\n",
      "Steps: 122415/156300 \t loss (ema): 0.062 \t Time elapsed: 8.188 hr\n",
      "Steps: 122515/156300 \t loss (ema): 0.049 \t Time elapsed: 8.195 hr\n",
      "Steps: 122615/156300 \t loss (ema): 0.065 \t Time elapsed: 8.201 hr\n",
      "Steps: 122715/156300 \t loss (ema): 0.051 \t Time elapsed: 8.208 hr\n",
      "Steps: 122815/156300 \t loss (ema): 0.043 \t Time elapsed: 8.215 hr\n",
      "Steps: 122915/156300 \t loss (ema): 0.058 \t Time elapsed: 8.221 hr\n",
      "Steps: 123015/156300 \t loss (ema): 0.050 \t Time elapsed: 8.228 hr\n",
      "Steps: 123115/156300 \t loss (ema): 0.050 \t Time elapsed: 8.235 hr\n",
      "Steps: 123215/156300 \t loss (ema): 0.054 \t Time elapsed: 8.241 hr\n",
      "Steps: 123315/156300 \t loss (ema): 0.053 \t Time elapsed: 8.248 hr\n",
      "Steps: 123415/156300 \t loss (ema): 0.053 \t Time elapsed: 8.255 hr\n",
      "Steps: 123478/156300 \t loss (ema): 0.053 \t Time elapsed: 8.259 hr\n",
      "Steps: 123578/156300 \t loss (ema): 0.054 \t Time elapsed: 8.266 hr\n",
      "Steps: 123678/156300 \t loss (ema): 0.054 \t Time elapsed: 8.273 hr\n",
      "Steps: 123778/156300 \t loss (ema): 0.055 \t Time elapsed: 8.279 hr\n",
      "Steps: 123878/156300 \t loss (ema): 0.046 \t Time elapsed: 8.286 hr\n",
      "Steps: 123978/156300 \t loss (ema): 0.052 \t Time elapsed: 8.293 hr\n",
      "Steps: 124078/156300 \t loss (ema): 0.051 \t Time elapsed: 8.299 hr\n",
      "Steps: 124178/156300 \t loss (ema): 0.054 \t Time elapsed: 8.306 hr\n",
      "Steps: 124278/156300 \t loss (ema): 0.057 \t Time elapsed: 8.313 hr\n",
      "Steps: 124378/156300 \t loss (ema): 0.049 \t Time elapsed: 8.319 hr\n",
      "Steps: 124478/156300 \t loss (ema): 0.051 \t Time elapsed: 8.326 hr\n",
      "Steps: 124578/156300 \t loss (ema): 0.054 \t Time elapsed: 8.332 hr\n",
      "Steps: 124678/156300 \t loss (ema): 0.056 \t Time elapsed: 8.339 hr\n",
      "Steps: 124778/156300 \t loss (ema): 0.057 \t Time elapsed: 8.346 hr\n",
      "Steps: 124878/156300 \t loss (ema): 0.056 \t Time elapsed: 8.352 hr\n",
      "Steps: 124978/156300 \t loss (ema): 0.048 \t Time elapsed: 8.359 hr\n",
      "Steps: 125041/156300 \t loss (ema): 0.056 \t Time elapsed: 8.363 hr\n",
      "Steps: 125141/156300 \t loss (ema): 0.050 \t Time elapsed: 8.370 hr\n",
      "Steps: 125241/156300 \t loss (ema): 0.043 \t Time elapsed: 8.377 hr\n",
      "Steps: 125341/156300 \t loss (ema): 0.045 \t Time elapsed: 8.383 hr\n",
      "Steps: 125441/156300 \t loss (ema): 0.051 \t Time elapsed: 8.390 hr\n",
      "Steps: 125541/156300 \t loss (ema): 0.057 \t Time elapsed: 8.397 hr\n",
      "Steps: 125641/156300 \t loss (ema): 0.057 \t Time elapsed: 8.403 hr\n",
      "Steps: 125741/156300 \t loss (ema): 0.055 \t Time elapsed: 8.410 hr\n",
      "Steps: 125841/156300 \t loss (ema): 0.065 \t Time elapsed: 8.417 hr\n",
      "Steps: 125941/156300 \t loss (ema): 0.061 \t Time elapsed: 8.424 hr\n",
      "Steps: 126041/156300 \t loss (ema): 0.050 \t Time elapsed: 8.430 hr\n",
      "Steps: 126141/156300 \t loss (ema): 0.052 \t Time elapsed: 8.437 hr\n",
      "Steps: 126241/156300 \t loss (ema): 0.050 \t Time elapsed: 8.444 hr\n",
      "Steps: 126341/156300 \t loss (ema): 0.050 \t Time elapsed: 8.450 hr\n",
      "Steps: 126441/156300 \t loss (ema): 0.052 \t Time elapsed: 8.457 hr\n",
      "Steps: 126541/156300 \t loss (ema): 0.051 \t Time elapsed: 8.463 hr\n",
      "Epoch 80 completed\n",
      "Steps: 126604/156300 \t loss (ema): 0.055 \t Time elapsed: 8.468 hr\n",
      "Steps: 126704/156300 \t loss (ema): 0.052 \t Time elapsed: 8.475 hr\n",
      "Steps: 126804/156300 \t loss (ema): 0.047 \t Time elapsed: 8.481 hr\n",
      "Steps: 126904/156300 \t loss (ema): 0.051 \t Time elapsed: 8.488 hr\n",
      "Steps: 127004/156300 \t loss (ema): 0.048 \t Time elapsed: 8.494 hr\n",
      "Steps: 127104/156300 \t loss (ema): 0.050 \t Time elapsed: 8.501 hr\n",
      "Steps: 127204/156300 \t loss (ema): 0.048 \t Time elapsed: 8.508 hr\n",
      "Steps: 127304/156300 \t loss (ema): 0.052 \t Time elapsed: 8.515 hr\n",
      "Steps: 127404/156300 \t loss (ema): 0.058 \t Time elapsed: 8.521 hr\n",
      "Steps: 127504/156300 \t loss (ema): 0.051 \t Time elapsed: 8.528 hr\n",
      "Steps: 127604/156300 \t loss (ema): 0.052 \t Time elapsed: 8.535 hr\n",
      "Steps: 127704/156300 \t loss (ema): 0.049 \t Time elapsed: 8.541 hr\n",
      "Steps: 127804/156300 \t loss (ema): 0.049 \t Time elapsed: 8.548 hr\n",
      "Steps: 127904/156300 \t loss (ema): 0.052 \t Time elapsed: 8.555 hr\n",
      "Steps: 128004/156300 \t loss (ema): 0.065 \t Time elapsed: 8.561 hr\n",
      "Steps: 128104/156300 \t loss (ema): 0.051 \t Time elapsed: 8.568 hr\n",
      "Steps: 128167/156300 \t loss (ema): 0.047 \t Time elapsed: 8.572 hr\n",
      "Steps: 128267/156300 \t loss (ema): 0.058 \t Time elapsed: 8.579 hr\n",
      "Steps: 128367/156300 \t loss (ema): 0.041 \t Time elapsed: 8.586 hr\n",
      "Steps: 128467/156300 \t loss (ema): 0.057 \t Time elapsed: 8.592 hr\n",
      "Steps: 128567/156300 \t loss (ema): 0.049 \t Time elapsed: 8.599 hr\n",
      "Steps: 128667/156300 \t loss (ema): 0.048 \t Time elapsed: 8.606 hr\n",
      "Steps: 128767/156300 \t loss (ema): 0.060 \t Time elapsed: 8.613 hr\n",
      "Steps: 128867/156300 \t loss (ema): 0.048 \t Time elapsed: 8.619 hr\n",
      "Steps: 128967/156300 \t loss (ema): 0.046 \t Time elapsed: 8.626 hr\n",
      "Steps: 129067/156300 \t loss (ema): 0.056 \t Time elapsed: 8.633 hr\n",
      "Steps: 129167/156300 \t loss (ema): 0.054 \t Time elapsed: 8.639 hr\n",
      "Steps: 129267/156300 \t loss (ema): 0.055 \t Time elapsed: 8.646 hr\n",
      "Steps: 129367/156300 \t loss (ema): 0.057 \t Time elapsed: 8.653 hr\n",
      "Steps: 129467/156300 \t loss (ema): 0.049 \t Time elapsed: 8.659 hr\n",
      "Steps: 129567/156300 \t loss (ema): 0.050 \t Time elapsed: 8.666 hr\n",
      "Steps: 129667/156300 \t loss (ema): 0.060 \t Time elapsed: 8.673 hr\n",
      "Steps: 129730/156300 \t loss (ema): 0.057 \t Time elapsed: 8.677 hr\n",
      "Steps: 129830/156300 \t loss (ema): 0.051 \t Time elapsed: 8.683 hr\n",
      "Steps: 129930/156300 \t loss (ema): 0.058 \t Time elapsed: 8.690 hr\n",
      "Steps: 130030/156300 \t loss (ema): 0.064 \t Time elapsed: 8.697 hr\n",
      "Steps: 130130/156300 \t loss (ema): 0.055 \t Time elapsed: 8.703 hr\n",
      "Steps: 130230/156300 \t loss (ema): 0.048 \t Time elapsed: 8.710 hr\n",
      "Steps: 130330/156300 \t loss (ema): 0.051 \t Time elapsed: 8.717 hr\n",
      "Steps: 130430/156300 \t loss (ema): 0.055 \t Time elapsed: 8.724 hr\n",
      "Steps: 130530/156300 \t loss (ema): 0.051 \t Time elapsed: 8.730 hr\n",
      "Steps: 130630/156300 \t loss (ema): 0.050 \t Time elapsed: 8.737 hr\n",
      "Steps: 130730/156300 \t loss (ema): 0.047 \t Time elapsed: 8.744 hr\n",
      "Steps: 130830/156300 \t loss (ema): 0.064 \t Time elapsed: 8.750 hr\n",
      "Steps: 130930/156300 \t loss (ema): 0.052 \t Time elapsed: 8.757 hr\n",
      "Steps: 131030/156300 \t loss (ema): 0.060 \t Time elapsed: 8.764 hr\n",
      "Steps: 131130/156300 \t loss (ema): 0.054 \t Time elapsed: 8.770 hr\n",
      "Steps: 131230/156300 \t loss (ema): 0.053 \t Time elapsed: 8.777 hr\n",
      "Steps: 131293/156300 \t loss (ema): 0.050 \t Time elapsed: 8.781 hr\n",
      "Steps: 131393/156300 \t loss (ema): 0.049 \t Time elapsed: 8.788 hr\n",
      "Steps: 131493/156300 \t loss (ema): 0.057 \t Time elapsed: 8.795 hr\n",
      "Steps: 131593/156300 \t loss (ema): 0.057 \t Time elapsed: 8.801 hr\n",
      "Steps: 131693/156300 \t loss (ema): 0.056 \t Time elapsed: 8.808 hr\n",
      "Steps: 131793/156300 \t loss (ema): 0.055 \t Time elapsed: 8.814 hr\n",
      "Steps: 131893/156300 \t loss (ema): 0.049 \t Time elapsed: 8.821 hr\n",
      "Steps: 131993/156300 \t loss (ema): 0.062 \t Time elapsed: 8.828 hr\n",
      "Steps: 132093/156300 \t loss (ema): 0.052 \t Time elapsed: 8.834 hr\n",
      "Steps: 132193/156300 \t loss (ema): 0.050 \t Time elapsed: 8.841 hr\n",
      "Steps: 132293/156300 \t loss (ema): 0.053 \t Time elapsed: 8.848 hr\n",
      "Steps: 132393/156300 \t loss (ema): 0.052 \t Time elapsed: 8.854 hr\n",
      "Steps: 132493/156300 \t loss (ema): 0.053 \t Time elapsed: 8.861 hr\n",
      "Steps: 132593/156300 \t loss (ema): 0.048 \t Time elapsed: 8.868 hr\n",
      "Steps: 132693/156300 \t loss (ema): 0.057 \t Time elapsed: 8.875 hr\n",
      "Steps: 132793/156300 \t loss (ema): 0.044 \t Time elapsed: 8.881 hr\n",
      "Steps: 132856/156300 \t loss (ema): 0.058 \t Time elapsed: 8.886 hr\n",
      "Steps: 132956/156300 \t loss (ema): 0.056 \t Time elapsed: 8.892 hr\n",
      "Steps: 133056/156300 \t loss (ema): 0.057 \t Time elapsed: 8.899 hr\n",
      "Steps: 133156/156300 \t loss (ema): 0.037 \t Time elapsed: 8.906 hr\n",
      "Steps: 133256/156300 \t loss (ema): 0.054 \t Time elapsed: 8.912 hr\n",
      "Steps: 133356/156300 \t loss (ema): 0.051 \t Time elapsed: 8.919 hr\n",
      "Steps: 133456/156300 \t loss (ema): 0.062 \t Time elapsed: 8.926 hr\n",
      "Steps: 133556/156300 \t loss (ema): 0.054 \t Time elapsed: 8.932 hr\n",
      "Steps: 133656/156300 \t loss (ema): 0.047 \t Time elapsed: 8.939 hr\n",
      "Steps: 133756/156300 \t loss (ema): 0.057 \t Time elapsed: 8.946 hr\n",
      "Steps: 133856/156300 \t loss (ema): 0.049 \t Time elapsed: 8.952 hr\n",
      "Steps: 133956/156300 \t loss (ema): 0.055 \t Time elapsed: 8.959 hr\n",
      "Steps: 134056/156300 \t loss (ema): 0.052 \t Time elapsed: 8.966 hr\n",
      "Steps: 134156/156300 \t loss (ema): 0.057 \t Time elapsed: 8.973 hr\n",
      "Steps: 134256/156300 \t loss (ema): 0.059 \t Time elapsed: 8.979 hr\n",
      "Steps: 134356/156300 \t loss (ema): 0.047 \t Time elapsed: 8.986 hr\n",
      "Steps: 134419/156300 \t loss (ema): 0.061 \t Time elapsed: 8.990 hr\n",
      "Steps: 134519/156300 \t loss (ema): 0.043 \t Time elapsed: 8.997 hr\n",
      "Steps: 134619/156300 \t loss (ema): 0.048 \t Time elapsed: 9.003 hr\n",
      "Steps: 134719/156300 \t loss (ema): 0.051 \t Time elapsed: 9.010 hr\n",
      "Steps: 134819/156300 \t loss (ema): 0.048 \t Time elapsed: 9.017 hr\n",
      "Steps: 134919/156300 \t loss (ema): 0.054 \t Time elapsed: 9.023 hr\n",
      "Steps: 135019/156300 \t loss (ema): 0.042 \t Time elapsed: 9.030 hr\n",
      "Steps: 135119/156300 \t loss (ema): 0.051 \t Time elapsed: 9.036 hr\n",
      "Steps: 135219/156300 \t loss (ema): 0.056 \t Time elapsed: 9.043 hr\n",
      "Steps: 135319/156300 \t loss (ema): 0.051 \t Time elapsed: 9.049 hr\n",
      "Steps: 135419/156300 \t loss (ema): 0.049 \t Time elapsed: 9.055 hr\n",
      "Steps: 135519/156300 \t loss (ema): 0.055 \t Time elapsed: 9.062 hr\n",
      "Steps: 135619/156300 \t loss (ema): 0.047 \t Time elapsed: 9.068 hr\n",
      "Steps: 135719/156300 \t loss (ema): 0.052 \t Time elapsed: 9.075 hr\n",
      "Steps: 135819/156300 \t loss (ema): 0.052 \t Time elapsed: 9.081 hr\n",
      "Steps: 135919/156300 \t loss (ema): 0.056 \t Time elapsed: 9.087 hr\n",
      "Steps: 135982/156300 \t loss (ema): 0.047 \t Time elapsed: 9.091 hr\n",
      "Steps: 136082/156300 \t loss (ema): 0.060 \t Time elapsed: 9.098 hr\n",
      "Steps: 136182/156300 \t loss (ema): 0.056 \t Time elapsed: 9.104 hr\n",
      "Steps: 136282/156300 \t loss (ema): 0.047 \t Time elapsed: 9.111 hr\n",
      "Steps: 136382/156300 \t loss (ema): 0.049 \t Time elapsed: 9.117 hr\n",
      "Steps: 136482/156300 \t loss (ema): 0.053 \t Time elapsed: 9.123 hr\n",
      "Steps: 136582/156300 \t loss (ema): 0.056 \t Time elapsed: 9.130 hr\n",
      "Steps: 136682/156300 \t loss (ema): 0.049 \t Time elapsed: 9.136 hr\n",
      "Steps: 136782/156300 \t loss (ema): 0.056 \t Time elapsed: 9.143 hr\n",
      "Steps: 136882/156300 \t loss (ema): 0.051 \t Time elapsed: 9.149 hr\n",
      "Steps: 136982/156300 \t loss (ema): 0.052 \t Time elapsed: 9.155 hr\n",
      "Steps: 137082/156300 \t loss (ema): 0.053 \t Time elapsed: 9.162 hr\n",
      "Steps: 137182/156300 \t loss (ema): 0.051 \t Time elapsed: 9.168 hr\n",
      "Steps: 137282/156300 \t loss (ema): 0.054 \t Time elapsed: 9.175 hr\n",
      "Steps: 137382/156300 \t loss (ema): 0.055 \t Time elapsed: 9.181 hr\n",
      "Steps: 137482/156300 \t loss (ema): 0.048 \t Time elapsed: 9.187 hr\n",
      "Steps: 137545/156300 \t loss (ema): 0.055 \t Time elapsed: 9.191 hr\n",
      "Steps: 137645/156300 \t loss (ema): 0.045 \t Time elapsed: 9.198 hr\n",
      "Steps: 137745/156300 \t loss (ema): 0.055 \t Time elapsed: 9.204 hr\n",
      "Steps: 137845/156300 \t loss (ema): 0.052 \t Time elapsed: 9.211 hr\n",
      "Steps: 137945/156300 \t loss (ema): 0.056 \t Time elapsed: 9.217 hr\n",
      "Steps: 138045/156300 \t loss (ema): 0.055 \t Time elapsed: 9.223 hr\n",
      "Steps: 138145/156300 \t loss (ema): 0.057 \t Time elapsed: 9.230 hr\n",
      "Steps: 138245/156300 \t loss (ema): 0.054 \t Time elapsed: 9.236 hr\n",
      "Steps: 138345/156300 \t loss (ema): 0.054 \t Time elapsed: 9.242 hr\n",
      "Steps: 138445/156300 \t loss (ema): 0.051 \t Time elapsed: 9.249 hr\n",
      "Steps: 138545/156300 \t loss (ema): 0.055 \t Time elapsed: 9.255 hr\n",
      "Steps: 138645/156300 \t loss (ema): 0.052 \t Time elapsed: 9.262 hr\n",
      "Steps: 138745/156300 \t loss (ema): 0.046 \t Time elapsed: 9.268 hr\n",
      "Steps: 138845/156300 \t loss (ema): 0.047 \t Time elapsed: 9.274 hr\n",
      "Steps: 138945/156300 \t loss (ema): 0.058 \t Time elapsed: 9.281 hr\n",
      "Steps: 139045/156300 \t loss (ema): 0.056 \t Time elapsed: 9.287 hr\n",
      "Steps: 139108/156300 \t loss (ema): 0.052 \t Time elapsed: 9.291 hr\n",
      "Steps: 139208/156300 \t loss (ema): 0.050 \t Time elapsed: 9.298 hr\n",
      "Steps: 139308/156300 \t loss (ema): 0.048 \t Time elapsed: 9.304 hr\n",
      "Steps: 139408/156300 \t loss (ema): 0.041 \t Time elapsed: 9.310 hr\n",
      "Steps: 139508/156300 \t loss (ema): 0.054 \t Time elapsed: 9.317 hr\n",
      "Steps: 139608/156300 \t loss (ema): 0.054 \t Time elapsed: 9.323 hr\n",
      "Steps: 139708/156300 \t loss (ema): 0.053 \t Time elapsed: 9.330 hr\n",
      "Steps: 139808/156300 \t loss (ema): 0.051 \t Time elapsed: 9.336 hr\n",
      "Steps: 139908/156300 \t loss (ema): 0.052 \t Time elapsed: 9.342 hr\n",
      "Steps: 140008/156300 \t loss (ema): 0.051 \t Time elapsed: 9.349 hr\n",
      "Steps: 140108/156300 \t loss (ema): 0.051 \t Time elapsed: 9.355 hr\n",
      "Steps: 140208/156300 \t loss (ema): 0.046 \t Time elapsed: 9.361 hr\n",
      "Steps: 140308/156300 \t loss (ema): 0.056 \t Time elapsed: 9.368 hr\n",
      "Steps: 140408/156300 \t loss (ema): 0.048 \t Time elapsed: 9.374 hr\n",
      "Steps: 140508/156300 \t loss (ema): 0.055 \t Time elapsed: 9.381 hr\n",
      "Steps: 140608/156300 \t loss (ema): 0.056 \t Time elapsed: 9.387 hr\n",
      "Steps: 140671/156300 \t loss (ema): 0.066 \t Time elapsed: 9.391 hr\n",
      "Steps: 140771/156300 \t loss (ema): 0.054 \t Time elapsed: 9.397 hr\n",
      "Steps: 140871/156300 \t loss (ema): 0.050 \t Time elapsed: 9.404 hr\n",
      "Steps: 140971/156300 \t loss (ema): 0.050 \t Time elapsed: 9.410 hr\n",
      "Steps: 141071/156300 \t loss (ema): 0.060 \t Time elapsed: 9.417 hr\n",
      "Steps: 141171/156300 \t loss (ema): 0.052 \t Time elapsed: 9.423 hr\n",
      "Steps: 141271/156300 \t loss (ema): 0.061 \t Time elapsed: 9.429 hr\n",
      "Steps: 141371/156300 \t loss (ema): 0.054 \t Time elapsed: 9.436 hr\n",
      "Steps: 141471/156300 \t loss (ema): 0.055 \t Time elapsed: 9.442 hr\n",
      "Steps: 141571/156300 \t loss (ema): 0.049 \t Time elapsed: 9.449 hr\n",
      "Steps: 141671/156300 \t loss (ema): 0.056 \t Time elapsed: 9.455 hr\n",
      "Steps: 141771/156300 \t loss (ema): 0.052 \t Time elapsed: 9.461 hr\n",
      "Steps: 141871/156300 \t loss (ema): 0.051 \t Time elapsed: 9.468 hr\n",
      "Steps: 141971/156300 \t loss (ema): 0.049 \t Time elapsed: 9.474 hr\n",
      "Steps: 142071/156300 \t loss (ema): 0.046 \t Time elapsed: 9.480 hr\n",
      "Steps: 142171/156300 \t loss (ema): 0.057 \t Time elapsed: 9.487 hr\n",
      "Epoch 90 completed\n",
      "Steps: 142234/156300 \t loss (ema): 0.055 \t Time elapsed: 9.491 hr\n",
      "Steps: 142334/156300 \t loss (ema): 0.052 \t Time elapsed: 9.497 hr\n",
      "Steps: 142434/156300 \t loss (ema): 0.058 \t Time elapsed: 9.504 hr\n",
      "Steps: 142534/156300 \t loss (ema): 0.044 \t Time elapsed: 9.510 hr\n",
      "Steps: 142634/156300 \t loss (ema): 0.059 \t Time elapsed: 9.517 hr\n",
      "Steps: 142734/156300 \t loss (ema): 0.050 \t Time elapsed: 9.523 hr\n",
      "Steps: 142834/156300 \t loss (ema): 0.043 \t Time elapsed: 9.529 hr\n",
      "Steps: 142934/156300 \t loss (ema): 0.059 \t Time elapsed: 9.536 hr\n",
      "Steps: 143034/156300 \t loss (ema): 0.057 \t Time elapsed: 9.542 hr\n",
      "Steps: 143134/156300 \t loss (ema): 0.053 \t Time elapsed: 9.549 hr\n",
      "Steps: 143234/156300 \t loss (ema): 0.053 \t Time elapsed: 9.555 hr\n",
      "Steps: 143334/156300 \t loss (ema): 0.053 \t Time elapsed: 9.561 hr\n",
      "Steps: 143434/156300 \t loss (ema): 0.054 \t Time elapsed: 9.568 hr\n",
      "Steps: 143534/156300 \t loss (ema): 0.059 \t Time elapsed: 9.574 hr\n",
      "Steps: 143634/156300 \t loss (ema): 0.053 \t Time elapsed: 9.581 hr\n",
      "Steps: 143734/156300 \t loss (ema): 0.059 \t Time elapsed: 9.588 hr\n",
      "Steps: 143797/156300 \t loss (ema): 0.052 \t Time elapsed: 9.592 hr\n",
      "Steps: 143897/156300 \t loss (ema): 0.057 \t Time elapsed: 9.598 hr\n",
      "Steps: 143997/156300 \t loss (ema): 0.051 \t Time elapsed: 9.605 hr\n",
      "Steps: 144097/156300 \t loss (ema): 0.060 \t Time elapsed: 9.611 hr\n",
      "Steps: 144197/156300 \t loss (ema): 0.051 \t Time elapsed: 9.618 hr\n",
      "Steps: 144297/156300 \t loss (ema): 0.047 \t Time elapsed: 9.624 hr\n",
      "Steps: 144397/156300 \t loss (ema): 0.056 \t Time elapsed: 9.631 hr\n",
      "Steps: 144497/156300 \t loss (ema): 0.047 \t Time elapsed: 9.638 hr\n",
      "Steps: 144597/156300 \t loss (ema): 0.053 \t Time elapsed: 9.644 hr\n",
      "Steps: 144697/156300 \t loss (ema): 0.054 \t Time elapsed: 9.651 hr\n",
      "Steps: 144797/156300 \t loss (ema): 0.056 \t Time elapsed: 9.657 hr\n",
      "Steps: 144897/156300 \t loss (ema): 0.052 \t Time elapsed: 9.664 hr\n",
      "Steps: 144997/156300 \t loss (ema): 0.057 \t Time elapsed: 9.670 hr\n",
      "Steps: 145097/156300 \t loss (ema): 0.059 \t Time elapsed: 9.677 hr\n",
      "Steps: 145197/156300 \t loss (ema): 0.045 \t Time elapsed: 9.683 hr\n",
      "Steps: 145297/156300 \t loss (ema): 0.051 \t Time elapsed: 9.690 hr\n",
      "Steps: 145360/156300 \t loss (ema): 0.049 \t Time elapsed: 9.694 hr\n",
      "Steps: 145460/156300 \t loss (ema): 0.059 \t Time elapsed: 9.701 hr\n",
      "Steps: 145560/156300 \t loss (ema): 0.053 \t Time elapsed: 9.707 hr\n",
      "Steps: 145660/156300 \t loss (ema): 0.050 \t Time elapsed: 9.714 hr\n",
      "Steps: 145760/156300 \t loss (ema): 0.051 \t Time elapsed: 9.720 hr\n",
      "Steps: 145860/156300 \t loss (ema): 0.054 \t Time elapsed: 9.727 hr\n",
      "Steps: 145960/156300 \t loss (ema): 0.048 \t Time elapsed: 9.734 hr\n",
      "Steps: 146060/156300 \t loss (ema): 0.061 \t Time elapsed: 9.740 hr\n",
      "Steps: 146160/156300 \t loss (ema): 0.053 \t Time elapsed: 9.747 hr\n",
      "Steps: 146260/156300 \t loss (ema): 0.052 \t Time elapsed: 9.753 hr\n",
      "Steps: 146360/156300 \t loss (ema): 0.060 \t Time elapsed: 9.760 hr\n",
      "Steps: 146460/156300 \t loss (ema): 0.056 \t Time elapsed: 9.766 hr\n",
      "Steps: 146560/156300 \t loss (ema): 0.051 \t Time elapsed: 9.773 hr\n",
      "Steps: 146660/156300 \t loss (ema): 0.051 \t Time elapsed: 9.779 hr\n",
      "Steps: 146760/156300 \t loss (ema): 0.059 \t Time elapsed: 9.786 hr\n",
      "Steps: 146860/156300 \t loss (ema): 0.065 \t Time elapsed: 9.793 hr\n",
      "Steps: 146923/156300 \t loss (ema): 0.050 \t Time elapsed: 9.797 hr\n",
      "Steps: 147023/156300 \t loss (ema): 0.056 \t Time elapsed: 9.803 hr\n",
      "Steps: 147123/156300 \t loss (ema): 0.047 \t Time elapsed: 9.810 hr\n",
      "Steps: 147223/156300 \t loss (ema): 0.058 \t Time elapsed: 9.816 hr\n",
      "Steps: 147323/156300 \t loss (ema): 0.048 \t Time elapsed: 9.823 hr\n",
      "Steps: 147423/156300 \t loss (ema): 0.038 \t Time elapsed: 9.829 hr\n",
      "Steps: 147523/156300 \t loss (ema): 0.053 \t Time elapsed: 9.836 hr\n",
      "Steps: 147623/156300 \t loss (ema): 0.054 \t Time elapsed: 9.843 hr\n",
      "Steps: 147723/156300 \t loss (ema): 0.063 \t Time elapsed: 9.849 hr\n",
      "Steps: 147823/156300 \t loss (ema): 0.059 \t Time elapsed: 9.856 hr\n",
      "Steps: 147923/156300 \t loss (ema): 0.058 \t Time elapsed: 9.862 hr\n",
      "Steps: 148023/156300 \t loss (ema): 0.045 \t Time elapsed: 9.869 hr\n",
      "Steps: 148123/156300 \t loss (ema): 0.053 \t Time elapsed: 9.875 hr\n",
      "Steps: 148223/156300 \t loss (ema): 0.044 \t Time elapsed: 9.882 hr\n",
      "Steps: 148323/156300 \t loss (ema): 0.053 \t Time elapsed: 9.889 hr\n",
      "Steps: 148423/156300 \t loss (ema): 0.047 \t Time elapsed: 9.895 hr\n",
      "Steps: 148486/156300 \t loss (ema): 0.056 \t Time elapsed: 9.899 hr\n",
      "Steps: 148586/156300 \t loss (ema): 0.053 \t Time elapsed: 9.906 hr\n",
      "Steps: 148686/156300 \t loss (ema): 0.048 \t Time elapsed: 9.912 hr\n",
      "Steps: 148786/156300 \t loss (ema): 0.047 \t Time elapsed: 9.919 hr\n",
      "Steps: 148886/156300 \t loss (ema): 0.046 \t Time elapsed: 9.925 hr\n",
      "Steps: 148986/156300 \t loss (ema): 0.055 \t Time elapsed: 9.932 hr\n",
      "Steps: 149086/156300 \t loss (ema): 0.046 \t Time elapsed: 9.938 hr\n",
      "Steps: 149186/156300 \t loss (ema): 0.050 \t Time elapsed: 9.945 hr\n",
      "Steps: 149286/156300 \t loss (ema): 0.060 \t Time elapsed: 9.951 hr\n",
      "Steps: 149386/156300 \t loss (ema): 0.056 \t Time elapsed: 9.957 hr\n",
      "Steps: 149486/156300 \t loss (ema): 0.057 \t Time elapsed: 9.964 hr\n",
      "Steps: 149586/156300 \t loss (ema): 0.044 \t Time elapsed: 9.971 hr\n",
      "Steps: 149686/156300 \t loss (ema): 0.050 \t Time elapsed: 9.977 hr\n",
      "Steps: 149786/156300 \t loss (ema): 0.052 \t Time elapsed: 9.984 hr\n",
      "Steps: 149886/156300 \t loss (ema): 0.049 \t Time elapsed: 9.990 hr\n",
      "Steps: 149986/156300 \t loss (ema): 0.052 \t Time elapsed: 9.997 hr\n",
      "Steps: 150049/156300 \t loss (ema): 0.053 \t Time elapsed: 10.001 hr\n",
      "Steps: 150149/156300 \t loss (ema): 0.052 \t Time elapsed: 10.008 hr\n",
      "Steps: 150249/156300 \t loss (ema): 0.057 \t Time elapsed: 10.014 hr\n",
      "Steps: 150349/156300 \t loss (ema): 0.053 \t Time elapsed: 10.021 hr\n",
      "Steps: 150449/156300 \t loss (ema): 0.054 \t Time elapsed: 10.027 hr\n",
      "Steps: 150549/156300 \t loss (ema): 0.053 \t Time elapsed: 10.034 hr\n",
      "Steps: 150649/156300 \t loss (ema): 0.051 \t Time elapsed: 10.040 hr\n",
      "Steps: 150749/156300 \t loss (ema): 0.049 \t Time elapsed: 10.047 hr\n",
      "Steps: 150849/156300 \t loss (ema): 0.052 \t Time elapsed: 10.054 hr\n",
      "Steps: 150949/156300 \t loss (ema): 0.049 \t Time elapsed: 10.060 hr\n",
      "Steps: 151049/156300 \t loss (ema): 0.050 \t Time elapsed: 10.067 hr\n",
      "Steps: 151149/156300 \t loss (ema): 0.056 \t Time elapsed: 10.073 hr\n",
      "Steps: 151249/156300 \t loss (ema): 0.059 \t Time elapsed: 10.080 hr\n",
      "Steps: 151349/156300 \t loss (ema): 0.057 \t Time elapsed: 10.087 hr\n",
      "Steps: 151449/156300 \t loss (ema): 0.049 \t Time elapsed: 10.093 hr\n",
      "Steps: 151549/156300 \t loss (ema): 0.052 \t Time elapsed: 10.100 hr\n",
      "Steps: 151612/156300 \t loss (ema): 0.046 \t Time elapsed: 10.104 hr\n",
      "Steps: 151712/156300 \t loss (ema): 0.059 \t Time elapsed: 10.111 hr\n",
      "Steps: 151812/156300 \t loss (ema): 0.064 \t Time elapsed: 10.117 hr\n",
      "Steps: 151912/156300 \t loss (ema): 0.047 \t Time elapsed: 10.124 hr\n",
      "Steps: 152012/156300 \t loss (ema): 0.044 \t Time elapsed: 10.130 hr\n",
      "Steps: 152112/156300 \t loss (ema): 0.044 \t Time elapsed: 10.137 hr\n",
      "Steps: 152212/156300 \t loss (ema): 0.054 \t Time elapsed: 10.143 hr\n",
      "Steps: 152312/156300 \t loss (ema): 0.050 \t Time elapsed: 10.150 hr\n",
      "Steps: 152412/156300 \t loss (ema): 0.053 \t Time elapsed: 10.156 hr\n",
      "Steps: 152512/156300 \t loss (ema): 0.058 \t Time elapsed: 10.163 hr\n",
      "Steps: 152612/156300 \t loss (ema): 0.039 \t Time elapsed: 10.169 hr\n",
      "Steps: 152712/156300 \t loss (ema): 0.049 \t Time elapsed: 10.176 hr\n",
      "Steps: 152812/156300 \t loss (ema): 0.057 \t Time elapsed: 10.182 hr\n",
      "Steps: 152912/156300 \t loss (ema): 0.058 \t Time elapsed: 10.189 hr\n",
      "Steps: 153012/156300 \t loss (ema): 0.048 \t Time elapsed: 10.195 hr\n",
      "Steps: 153112/156300 \t loss (ema): 0.050 \t Time elapsed: 10.201 hr\n",
      "Steps: 153175/156300 \t loss (ema): 0.055 \t Time elapsed: 10.206 hr\n",
      "Steps: 153275/156300 \t loss (ema): 0.046 \t Time elapsed: 10.212 hr\n",
      "Steps: 153375/156300 \t loss (ema): 0.056 \t Time elapsed: 10.218 hr\n",
      "Steps: 153475/156300 \t loss (ema): 0.055 \t Time elapsed: 10.225 hr\n",
      "Steps: 153575/156300 \t loss (ema): 0.057 \t Time elapsed: 10.231 hr\n",
      "Steps: 153675/156300 \t loss (ema): 0.061 \t Time elapsed: 10.238 hr\n",
      "Steps: 153775/156300 \t loss (ema): 0.052 \t Time elapsed: 10.244 hr\n",
      "Steps: 153875/156300 \t loss (ema): 0.055 \t Time elapsed: 10.251 hr\n",
      "Steps: 153975/156300 \t loss (ema): 0.040 \t Time elapsed: 10.257 hr\n",
      "Steps: 154075/156300 \t loss (ema): 0.054 \t Time elapsed: 10.264 hr\n",
      "Steps: 154175/156300 \t loss (ema): 0.050 \t Time elapsed: 10.270 hr\n",
      "Steps: 154275/156300 \t loss (ema): 0.044 \t Time elapsed: 10.277 hr\n",
      "Steps: 154375/156300 \t loss (ema): 0.048 \t Time elapsed: 10.283 hr\n",
      "Steps: 154475/156300 \t loss (ema): 0.053 \t Time elapsed: 10.290 hr\n",
      "Steps: 154575/156300 \t loss (ema): 0.053 \t Time elapsed: 10.296 hr\n",
      "Steps: 154675/156300 \t loss (ema): 0.048 \t Time elapsed: 10.303 hr\n",
      "Steps: 154738/156300 \t loss (ema): 0.056 \t Time elapsed: 10.307 hr\n",
      "Steps: 154838/156300 \t loss (ema): 0.050 \t Time elapsed: 10.313 hr\n",
      "Steps: 154938/156300 \t loss (ema): 0.051 \t Time elapsed: 10.320 hr\n",
      "Steps: 155038/156300 \t loss (ema): 0.057 \t Time elapsed: 10.326 hr\n",
      "Steps: 155138/156300 \t loss (ema): 0.043 \t Time elapsed: 10.333 hr\n",
      "Steps: 155238/156300 \t loss (ema): 0.053 \t Time elapsed: 10.339 hr\n",
      "Steps: 155338/156300 \t loss (ema): 0.050 \t Time elapsed: 10.346 hr\n",
      "Steps: 155438/156300 \t loss (ema): 0.055 \t Time elapsed: 10.352 hr\n",
      "Steps: 155538/156300 \t loss (ema): 0.046 \t Time elapsed: 10.359 hr\n",
      "Steps: 155638/156300 \t loss (ema): 0.048 \t Time elapsed: 10.365 hr\n",
      "Steps: 155738/156300 \t loss (ema): 0.047 \t Time elapsed: 10.372 hr\n",
      "Steps: 155838/156300 \t loss (ema): 0.061 \t Time elapsed: 10.378 hr\n",
      "Steps: 155938/156300 \t loss (ema): 0.055 \t Time elapsed: 10.385 hr\n",
      "Steps: 156038/156300 \t loss (ema): 0.053 \t Time elapsed: 10.391 hr\n",
      "Steps: 156138/156300 \t loss (ema): 0.051 \t Time elapsed: 10.398 hr\n",
      "Steps: 156238/156300 \t loss (ema): 0.058 \t Time elapsed: 10.404 hr\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    \n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(device)\n",
    "    # torch.cuda.set_device(device)\n",
    "    torch.manual_seed(123)\n",
    "    np.random.seed(123)\n",
    "\n",
    "\n",
    "    attention_ds = []\n",
    "    attention_resolutions = \"32,16,8\"\n",
    "\n",
    "    for res in attention_resolutions.split(\",\"):\n",
    "        attention_ds.append(metadata.image_size // int(res))\n",
    "    \n",
    "    model = models.UNetModel(image_size=metadata.image_size, \n",
    "                                in_channels=metadata.num_channels, \n",
    "                                out_channels=metadata.num_channels,\n",
    "                                model_channels = 64,\n",
    "                                channel_mult = (1, 2, 2, 2),\n",
    "                                num_res_blocks = 3,\n",
    "                                dropout = 0.1,\n",
    "                                num_classes=None,  # We're not using class labels\n",
    "                                use_checkpoint=False,\n",
    "                                use_fp16=False,\n",
    "                                num_heads=4,\n",
    "                                attention_resolutions=tuple(attention_ds),\n",
    "                                num_head_channels=64,\n",
    "                                num_heads_upsample=-1,\n",
    "                                use_scale_shift_norm=True,\n",
    "                                resblock_updown=True,\n",
    "                                use_new_attention_order=True\n",
    "                                ).to(device)\n",
    "    \n",
    "    diffusion_model = models.GaussianDiffusion(DIFFUSION_STEPS, device)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "    if PRETRAINED_MODEL == \"\":\n",
    "        print(\"Training from scratch\")\n",
    "    else:\n",
    "        print(f\"Loading pretrained model from {PRETRAINED_MODEL}\")\n",
    "        model.load_state_dict(torch.load(PRETRAINED_MODEL))\n",
    "\n",
    "    train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "    print(f\"Training dataset loaded: Number of batches: {len(train_loader)}, Number of images: {len(train_set)}\")\n",
    "    logger = loss_logger(len(train_loader) * EPOCHS)\n",
    "\n",
    "    ema_dict = copy.deepcopy(model.state_dict())\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        ema_dict = train_one_epoch(model, train_loader, diffusion_model, optimizer, logger, None, ema_dict, device)\n",
    "        if epoch % 10 == 0:\n",
    "            print(f\"Epoch {epoch} completed\")\n",
    "            torch.save(ema_dict, f\"{SAVE_MODEL_PATH}ema_dict_{epoch}.pt\")\n",
    "            torch.save(model.state_dict(), f\"{SAVE_MODEL_PATH}model_{epoch}.pt\")\n",
    "\n",
    "    torch.save(ema_dict, f\"{SAVE_MODEL_PATH}ema_dict_{epoch}.pt\")\n",
    "    torch.save(model.state_dict(), f\"{SAVE_MODEL_PATH}model_{epoch}.pt\")\n",
    "    \n",
    "    return 0\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Inference mode to generate images from the trained model\"\"\"\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "attention_ds = []\n",
    "attention_resolutions = \"32,16,8\"\n",
    "\n",
    "for res in attention_resolutions.split(\",\"):\n",
    "    attention_ds.append(metadata.image_size // int(res))\n",
    "\n",
    "model = models.UNetModel(image_size=metadata.image_size, \n",
    "                            in_channels=metadata.num_channels, \n",
    "                            out_channels=metadata.num_channels,\n",
    "                            model_channels = 64,\n",
    "                            channel_mult = (1, 2, 2, 2),\n",
    "                            num_res_blocks = 3,\n",
    "                            dropout = 0.1,\n",
    "                            num_classes=None,  # We're not using class labels\n",
    "                            use_checkpoint=False,\n",
    "                            use_fp16=False,\n",
    "                            num_heads=4,\n",
    "                            attention_resolutions=tuple(attention_ds),\n",
    "                            num_head_channels=64,\n",
    "                            num_heads_upsample=-1,\n",
    "                            use_scale_shift_norm=True,\n",
    "                            resblock_updown=True,\n",
    "                            use_new_attention_order=True\n",
    "                            ).to(device)\n",
    "\n",
    "load_model(model, \"./saved_models/model_100.pt\")\n",
    "\n",
    "diffusion_model = models.GaussianDiffusion(DIFFUSION_STEPS, device)\n",
    "\n",
    "# Generate images\n",
    "samples = generate_N_images(64, model, diffusion_model, xT=None, sampling_steps=250, batch_size=32, num_channels=3, image_size=32)\n",
    "\n",
    "cv2.imwrite(SAVE_IMAGES_PATH+train_set.__class__.__name__+str(DIFFUSION_STEPS)+\".jpeg\", np.concatenate(samples, axis=1)[:, :, ::-1],)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diffusion",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
